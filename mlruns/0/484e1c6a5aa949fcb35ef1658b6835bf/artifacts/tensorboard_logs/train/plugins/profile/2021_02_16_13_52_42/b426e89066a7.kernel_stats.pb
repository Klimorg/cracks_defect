
¬
›void cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)\Ñ*2à8õ∞ã@õ∞ãHõ∞ãXb8gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropFilterhu≥™&B
√
›void cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)\Ñ*2à8úËâ@úËâHúËâXb9gradient_tape/model/conv2d_14/Conv2D/Conv2DBackpropFilterhu≥™&B
√
›void cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)\Ñ*2à8õÄâ@õÄâHõÄâXb9gradient_tape/model/conv2d_11/Conv2D/Conv2DBackpropFilterhu≥™&B
¬
›void cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)\Ñ*2à8õÄâ@õÄâHõÄâXb8gradient_tape/model/conv2d_5/Conv2D/Conv2DBackpropFilterhu≥™&B
Ò=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28îò√@îò√Hîò√Xb9gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropFilterh
Ò=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28îê√@îê√Hîê√Xb9gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropFilterh
=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28îÄ√@îÄ√HîÄ√Xb8gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropFilterh
=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28îÄ√@îÄ√HîÄ√Xb8gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropFilterh
=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28î¯¬@î¯¬Hî¯¬Xb8gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropFilterh
¬
›void cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)\Ñ*2b8ë»£@ë»£Hë»£Xb9gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropFilterhu≥™&B
È
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8ê†°@ê†°Hê†°b?gradient_tape/model/batch_normalization_17/FusedBatchNormGradV3hu  »B
Ë
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8ê†@ê†Hê†b>gradient_tape/model/batch_normalization_4/FusedBatchNormGradV3hu  »B
Ë
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8ê¯ü@ê¯üHê¯üb>gradient_tape/model/batch_normalization_7/FusedBatchNormGradV3hu  »B
È
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8êËü@êËüHêËüb?gradient_tape/model/batch_normalization_10/FusedBatchNormGradV3hu  »B
È
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8ê∏ü@ê∏üHê∏üb?gradient_tape/model/batch_normalization_16/FusedBatchNormGradV3hu  »B
È
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8êòü@êòüHêòüb?gradient_tape/model/batch_normalization_13/FusedBatchNormGradV3hu  »B
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)Ï ÄÄ*Ä2Äb8çÄx@çÄxHçÄxPXbmodel/conv2d_15/Conv2Dh
•
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)Ï ÄÄ*Ä2Äb8çÄx@çÄxHçÄxPXbmodel/conv2d_9/Conv2Dh
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)Ï ÄÄ*Ä2Äb8å¯w@å¯wHå¯wPXbmodel/conv2d_12/Conv2Dh
•
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)Ï ÄÄ*Ä2Äb8å¯w@å¯wHå¯wPXbmodel/conv2d_3/Conv2Dh
•
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)Ï ÄÄ*Ä2Äb8å¯w@å¯wHå¯wPXbmodel/conv2d_6/Conv2Dh
£
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)Ï ÄÄ*Ä2Äb8åËu@åËuHåËuPXbmodel/conv2d/Conv2Dh
Î=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28ã»b@ã»bHã»bXb6gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilterh
Ì=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28äàb@äàbHäàbXb8gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropFilterh
Ì=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28äÄb@äÄbHäÄbXb8gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropFilterh
Ó=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28äÄb@äÄbHäÄbXb9gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropFilterh
Ó=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28ä¯a@ä¯aHä¯aXb9gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropFilterh
Ó=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28ä¯a@ä¯aHä¯aXb9gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ì=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28äa@äaHäaXb8gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ì=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params){ ÄÄ*Ä28äa@äaHäaXb8gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropFilterh
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä‡a@ä‡aHä‡ab?gradient_tape/model/batch_normalization_15/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä–a@ä–aHä–ab?gradient_tape/model/batch_normalization_12/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28â»a@â»aHâ»ab?gradient_tape/model/batch_normalization_14/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä¿a@ä¿aHä¿ab?gradient_tape/model/batch_normalization_11/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä¿a@ä¿aHä¿ab>gradient_tape/model/batch_normalization_5/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä¿a@ä¿aHä¿ab>gradient_tape/model/batch_normalization_8/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä¿a@ä¿aHä¿ab>gradient_tape/model/batch_normalization_9/FusedBatchNormGradV3hu  »B
„
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä∏a@ä∏aHä∏ab<gradient_tape/model/batch_normalization/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä∏a@ä∏aHä∏ab>gradient_tape/model/batch_normalization_1/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä∏a@ä∏aHä∏ab>gradient_tape/model/batch_normalization_6/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28ä®a@ä®aHä®ab>gradient_tape/model/batch_normalization_2/FusedBatchNormGradV3hu  »B
Â
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä28äòa@äòaHäòab>gradient_tape/model/batch_normalization_3/FusedBatchNormGradV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ä∞^@ä∞^Hä∞^b%gradient_tape/model/re_lu_17/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ä†^@ä†^Hä†^b$gradient_tape/model/re_lu_4/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äò^@äò^Häò^b%gradient_tape/model/re_lu_10/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ä–]@ä–]Hä–]b%gradient_tape/model/re_lu_16/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äê]@äê]Häê]b$gradient_tape/model/re_lu_7/ReluGradhuZUÖB
™
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äà]@äà]Häà]bAdam/gradients/AddN_10huZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8âà]@âà]Hâà]b%gradient_tape/model/re_lu_13/ReluGradhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8ä¿\@ä¿\Hä¿\b-model/batch_normalization_17/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8â¿\@â¿\Hâ¿\b,model/batch_normalization_7/FusedBatchNormV3hu  »B
™
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ä¯[@ä¯[Hä¯[bAdam/gradients/AddN_13huZUÖB
Ö
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äË[@äË[HäË[bmodel/add/addhuZUÖB
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äË[@äË[HäË[bmodel/add_3/addhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8âÄ[@âÄ[HâÄ[b-model/batch_normalization_13/FusedBatchNormV3hu  »B
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8â¿Z@â¿ZHâ¿ZbAdam/gradients/AddN_9huZUÖB
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äêZ@äêZHäêZbmodel/add_1/addhuZUÖB
™
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8âêZ@âêZHâêZbAdam/gradients/AddN_12huZUÖB
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8âÄZ@âÄZHâÄZbmodel/add_2/addhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8â¯Y@â¯YHâ¯Yb-model/batch_normalization_16/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8â¯Y@â¯YHâ¯Yb,model/batch_normalization_4/FusedBatchNormV3hu  »B
™
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8äËY@äËYHäËYbAdam/gradients/AddN_11huZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8âËY@âËYHâËYb-model/batch_normalization_10/FusedBatchNormV3hu  »B
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8â»Y@â»YHâ»Ybmodel/add_4/addhuZUÖB
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8â–W@â–WHâ–WXb8gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropInputhu  »A
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8â–W@â–WHâ–WXb7gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropInputhu  »A
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8â–W@â–WHâ–WXb7gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8â»W@â»WHâ»WXb8gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropInputhu  »A
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8â»W@â»WHâ»WXb7gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropInputhu  »A
–
Óvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)‡ ÄÄ*Ä28âàV@âàVHâàVPXb9gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropFilterh
–
Óvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)‡ ÄÄ*Ä28ààV@ààVHààVPXb9gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropFilterh
–
Óvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)‡ ÄÄ*Ä28âÄV@âÄVHâÄVPXb9gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropFilterh
–
Óvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)‡ ÄÄ*Ä28âÄV@âÄVHâÄVPXb9gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28â¯Q@â¯QHâ¯QXb9gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28â¯Q@â¯QHâ¯QXb9gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28à¯Q@à¯QHà¯QXb9gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28à¯Q@à¯QHà¯QXb9gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28àQ@àQHàQXb9gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropFilterh
ø
›void cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)\Ñ*2b8à∏Q@à∏QHà∏QXb9gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropFilterhu≥™&B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8ààL@ààLHààLb?gradient_tape/model/batch_normalization_29/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8à»J@à»JHà»Jb?gradient_tape/model/batch_normalization_33/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8à¿J@à¿JHà¿Jb?gradient_tape/model/batch_normalization_20/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8à®J@à®JHà®Jb?gradient_tape/model/batch_normalization_23/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8à†J@à†JHà†Jb?gradient_tape/model/batch_normalization_32/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8áàJ@áàJHáàJb?gradient_tape/model/batch_normalization_26/FusedBatchNormGradV3hu  »B
Û
ëvoid foldedNhwcToNchwKernel<float, float, float, true, (cudnnKernelDataType_t)0>(int, int, int, int, int, int, int, float const*, float*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä!* 2† 8á»>@á»>Há»>Xb8gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropInputhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ü¿>@Ü¿>HÜ¿>bmodel/re_lu_17/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ü‡=@Ü‡=HÜ‡=bmodel/re_lu_7/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ü∞=@Ü∞=HÜ∞=bmodel/re_lu_13/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Üê=@Üê=HÜê=bmodel/re_lu_4/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Üà=@Üà=HÜà=bmodel/re_lu_16/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ü¯<@Ü¯<HÜ¯<bmodel/re_lu_10/ReluhuZUÖB
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ü¯;@Ü¯;HÜ¯;Xb9gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Üÿ;@Üÿ;HÜÿ;Xb8gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ü®;@Ü®;HÜ®;Xb9gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ü®;@Ü®;HÜ®;Xb9gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ü®;@Ü®;HÜ®;Xbmodel/conv2d_17/Conv2Dhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ü†;@Ü†;HÜ†;Xb8gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Üò;@Üò;HÜò;Xb8gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
Û
ëvoid foldedNhwcToNchwKernel<float, float, float, true, (cudnnKernelDataType_t)0>(int, int, int, int, int, int, int, float const*, float*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä!* 2† 8Ü¯:@Ü¯:HÜ¯:Xb8gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
ã
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x256_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x256_16x4_unity_stride::Params)Í ÄÄ*Ä2Äƒ8Ü–9@Ü–9HÜ–9Xb8gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropInputh
∫
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äà8ÖË4@ÖË4HÖË4Xbmodel/conv2d_13/Conv2DhuZUÖB
∫
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äà8Ü∏4@Ü∏4HÜ∏4Xbmodel/conv2d_16/Conv2DhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äà8Ü∞4@Ü∞4HÜ∞4Xbmodel/conv2d_1/Conv2DhuZUÖB
∫
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äà8Ü∞4@Ü∞4HÜ∞4Xbmodel/conv2d_10/Conv2DhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äà8Ö∞4@Ö∞4HÖ∞4Xbmodel/conv2d_4/Conv2DhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äà8Ö∞4@Ö∞4HÖ∞4Xbmodel/conv2d_7/Conv2DhuZUÖB
»
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params) ÄÄ*Ä2¿8Öà3@Öà3HÖà3PXb8gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropInputh
÷
Ùvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params) ÄÄ*Ä2		8Ö¯2@Ö¯2HÖ¯2PXb9gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropFilterh
÷
Ùvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params) ÄÄ*Ä2		8Ö2@Ö2HÖ2PXb9gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropFilterh
÷
Ùvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params) ÄÄ*Ä2		8Ö2@Ö2HÖ2PXb9gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropFilterh
÷
Ùvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params) ÄÄ*Ä2		8Ü‡2@Ü‡2HÜ‡2PXb9gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropFilterh
÷
Ùvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params) ÄÄ*Ä2		8Ö‡2@Ö‡2HÖ‡2PXb9gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropFilterh
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö–/@Ö–/HÖ–/bmodel/add_8/addhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö∞/@Ö∞/HÖ∞/b%gradient_tape/model/re_lu_20/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö».@Ö».HÖ».b%gradient_tape/model/re_lu_23/ReluGradhuZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Ö».@Ö».HÖ».b-model/batch_normalization_29/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ñ».@Ñ».HÑ».b%gradient_tape/model/re_lu_32/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ñ¿.@Ñ¿.HÑ¿.b%gradient_tape/model/re_lu_33/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö∏.@Ö∏.HÖ∏.b%gradient_tape/model/re_lu_26/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Öò.@Öò.HÖò.b%gradient_tape/model/re_lu_29/ReluGradhuZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Öò.@Öò.HÖò.b-model/batch_normalization_26/FusedBatchNormV3hu  »B
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ñ‡-@Ñ‡-HÑ‡-bAdam/gradients/AddN_8huZUÖB
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Öÿ-@Öÿ-HÖÿ-bmodel/add_5/addhuZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Öÿ-@Öÿ-HÖÿ-b-model/batch_normalization_20/FusedBatchNormV3hu  »B
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Ñÿ-@Ñÿ-HÑÿ-b-model/batch_normalization_32/FusedBatchNormV3hu  »B
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñ»-@Ñ»-HÑ»-Xb8gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ö¿-@Ö¿-HÖ¿-Xb8gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropInputhu  »A
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö¿-@Ö¿-HÖ¿-bAdam/gradients/AddN_5huZUÖB
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñ¿-@Ñ¿-HÑ¿-Xb7gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInputhu  »A
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ö∏-@Ö∏-HÖ∏-Xb7gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropInputhu  »A
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ö∏-@Ö∏-HÖ∏-Xb7gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñ∏-@Ñ∏-HÑ∏-Xb8gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropInputhu  »A
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö∞-@Ö∞-HÖ∞-bAdam/gradients/AddN_4huZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Ö∞-@Ö∞-HÖ∞-b-model/batch_normalization_33/FusedBatchNormV3hu  »B
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Ñ®-@Ñ®-HÑ®-b-model/batch_normalization_23/FusedBatchNormV3hu  »B
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ñ†-@Ñ†-HÑ†-bmodel/add_9/addhuZUÖB
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÖÄ-@ÖÄ-HÖÄ-bmodel/add_7/addhuZUÖB
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ö¯,@Ö¯,HÖ¯,bAdam/gradients/AddN_6huZUÖB
á
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ñ¯,@Ñ¯,HÑ¯,bmodel/add_6/addhuZUÖB
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ñ¯,@Ñ¯,HÑ¯,bAdam/gradients/AddN_7huZUÖB
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8Ñò+@Ñò+HÑò+b?gradient_tape/model/batch_normalization_42/FusedBatchNormGradV3hu  »B
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28Ö∏*@Ö∏*HÖ∏*Xb9gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28Ö∏*@Ö∏*HÖ∏*Xb9gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28Ñ∏*@Ñ∏*HÑ∏*Xb9gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28Ñ∏*@Ñ∏*HÑ∏*Xb9gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params){ ÄÄ*Ä28Ñ∏*@Ñ∏*HÑ∏*Xb9gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropFilterh
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8Ñò)@Ñò)HÑò)b?gradient_tape/model/batch_normalization_48/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8Ñà)@Ñà)HÑà)b?gradient_tape/model/batch_normalization_39/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8Ñ‡(@Ñ‡(HÑ‡(b?gradient_tape/model/batch_normalization_36/FusedBatchNormGradV3hu  »B
Á
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2Ä8Ñÿ(@Ñÿ(HÑÿ(b?gradient_tape/model/batch_normalization_45/FusedBatchNormGradV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñ®'@Ñ®'HÑ®'b,model/batch_normalization_8/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñ†'@Ñ†'HÑ†'b,model/batch_normalization_2/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñò'@Ñò'HÑò'b-model/batch_normalization_14/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñò'@Ñò'HÑò'b,model/batch_normalization_5/FusedBatchNormV3hu  »B
ß
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñê'@Ñê'HÑê'b*model/batch_normalization/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñê'@Ñê'HÑê'b-model/batch_normalization_12/FusedBatchNormV3hu  »B
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñà'@Ñà'HÑà'Xb8gradient_tape/model/conv2d_11/Conv2D/Conv2DBackpropInputhu  »A
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñà'@Ñà'HÑà'b-model/batch_normalization_11/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Ñà'@Ñà'HÑà'b,model/batch_normalization_3/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28Éà'@Éà'HÉà'b,model/batch_normalization_6/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28ÑÄ'@ÑÄ'HÑÄ'b,model/batch_normalization_1/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28ÑÄ'@ÑÄ'HÑÄ'b-model/batch_normalization_15/FusedBatchNormV3hu  »B
©
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä28ÑÄ'@ÑÄ'HÑÄ'b,model/batch_normalization_9/FusedBatchNormV3hu  »B
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñÿ&@Ñÿ&HÑÿ&Xb7gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñ–&@Ñ–&HÑ–&Xb8gradient_tape/model/conv2d_14/Conv2D/Conv2DBackpropInputhu  »A
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8Ñ¿&@Ñ¿&HÑ¿&Xb7gradient_tape/model/conv2d_5/Conv2D/Conv2DBackpropInputhu  »A
–
pvoid cudnn::ops::convertTensor_kernel<float, float, float, 2>(float, float const*, float, float*, unsigned long)*Ä2Ä 8Ñ∞&@Å¯HÉ∏Xb9gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropFilterhu  »B
–
pvoid cudnn::ops::convertTensor_kernel<float, float, float, 2>(float, float const*, float, float*, unsigned long)*Ä2Ä 8É¯%@ÄÿHÉ†Xb9gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropFilterhu  »B
–
pvoid cudnn::ops::convertTensor_kernel<float, float, float, 2>(float, float const*, float, float*, unsigned long)*Ä2Ä 8Ñ‡%@ÅÿHÉàXb9gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropFilterhu  »B
–
pvoid cudnn::ops::convertTensor_kernel<float, float, float, 2>(float, float const*, float, float*, unsigned long)*Ä2Ä 8Ñ–%@Å–HÉÄXb9gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropFilterhu  »B
†
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äà8Ñ¿$@Ñ¿$HÑ¿$Xbmodel/conv2d_11/Conv2DhuZUÖB
†
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äà8Ñ∞$@Ñ∞$HÑ∞$Xbmodel/conv2d_14/Conv2DhuZUÖB
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äà8Ñ∞$@Ñ∞$HÑ∞$Xbmodel/conv2d_8/Conv2DhuZUÖB
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äà8Ñ®$@Ñ®$HÑ®$Xbmodel/conv2d_5/Conv2DhuZUÖB
Ï
åvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3::Params)ˆ Ä¿*Ä28ÑÄ$@ÑÄ$HÑÄ$Xb9gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropFilterh
Ï
åvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3::Params)ˆ Ä¿*Ä28ÑÄ$@ÑÄ$HÑÄ$Xb9gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropFilterh
Ï
åvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3::Params)ˆ Ä¿*Ä28ÉÄ$@ÉÄ$HÉÄ$Xb9gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropFilterh
Ï
åvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3::Params)ˆ Ä¿*Ä28Ñ¯#@Ñ¯#HÑ¯#Xb9gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropFilterh
Ï
åvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x256_16x3::Params)ˆ Ä¿*Ä28Ñ¯#@Ñ¯#HÑ¯#Xb9gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropFilterh
ã
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x256_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x256_16x4_unity_stride::Params)Í ÄÄ*Ä2Äƒ8É‡"@É‡"HÉ‡"Xb8gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropInputh
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8É@Å¯HÇ¯Xb9gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
§
‰void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)ˇ ÄÄ*Ä2¿8Éà@ÉàHÉàPXbmodel/conv2d_17/Conv2Dh
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É@ÉHÉbmodel/re_lu_23/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É@ÉHÉbmodel/re_lu_32/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É‡@É‡HÉ‡bmodel/re_lu_20/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É‡@É‡HÉ‡bmodel/re_lu_29/ReluhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äb8Éÿ@ÉÿHÉÿXbmodel/conv2d_20/Conv2DhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äb8É»@É»HÉ»Xbmodel/conv2d_32/Conv2DhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äb8É¿@É¿HÉ¿Xbmodel/conv2d_23/Conv2DhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äb8É¿@É¿HÉ¿Xbmodel/conv2d_26/Conv2DhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É∏@É∏HÉ∏bmodel/re_lu_26/ReluhuZUÖB
π
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)@Ä*2Äb8É∏@É∏HÉ∏Xbmodel/conv2d_29/Conv2DhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É∞@É∞HÉ∞bmodel/re_lu_33/ReluhuZUÖB
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É®@É®HÉ®Xb9gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É®@É®HÉ®Xb8gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8É†@ÇàHÅòXb8gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Éê@ÅÄHÇêXb8gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Éà@Å¯HÇêXb9gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8ÉÄ@ÉÄHÉÄXb9gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8ÉÄ@ÅÄHÇÄXb8gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É@ÉHÉXb9gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É@ÉHÉXb8gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É@ÉHÉXb8gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropInputhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8ÉË@ÉËHÉËXbmodel/conv2d_33/Conv2Dhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É‡@É‡HÉ‡Xb9gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É‡@É‡HÉ‡Xb8gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8É‡@ÇËHÅ¯Xb8gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropFilterhu  »B
Œ
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)† Ä¿*Ä2Äb8Éÿ@ÉÿHÉÿXbmodel/conv2d_19/Conv2Dh
Œ
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)† Ä¿*Ä2Äb8Éÿ@ÉÿHÉÿXbmodel/conv2d_31/Conv2Dh
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Éÿ@ÉÿHÉÿXb8gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Éÿ@ÉÿHÉÿXb9gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Éÿ@ÉÿHÉÿXb9gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Éÿ@ÉÿHÉÿXb9gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Éÿ@ÉÿHÉÿXb8gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Éÿ@ÉÿHÉÿXb8gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropInputhu  »B
Œ
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)† Ä¿*Ä2Äb8É–@É–HÉ–Xbmodel/conv2d_22/Conv2Dh
Œ
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)† Ä¿*Ä2Äb8É–@É–HÉ–Xbmodel/conv2d_25/Conv2Dh
Œ
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)† Ä¿*Ä2Äb8É–@É–HÉ–Xbmodel/conv2d_28/Conv2Dh
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É∏@É∏HÉ∏Xb8gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É∏@É∏HÉ∏Xb8gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8É∏@É∏HÉ∏Xb8gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropInputhu  »B
˝=
ù=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)ˇ ÄÄ*Ä28Éò@ÉòHÉòXb9gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropFilterh
˝=
ù=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)ˇ ÄÄ*Ä28Éò@ÉòHÉòXb9gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropFilterh
˝=
ù=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)ˇ ÄÄ*Ä28Éò@ÉòHÉòXb9gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropFilterh
˝=
ù=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 256>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 256, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<256, 8, 1, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)ˇ ÄÄ*Ä28Éê@ÉêHÉêXb9gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropFilterh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18É@ÉHÉXb8gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18É@ÉHÉXb8gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18ÇË@ÇËHÇËXb8gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18É‡@É‡HÉ‡Xb8gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18Éÿ@ÉÿHÉÿXb8gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropInputh
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8Çà@ÇàHÇàb?gradient_tape/model/batch_normalization_27/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8Éÿ@ÉÿHÉÿb?gradient_tape/model/batch_normalization_21/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8Éÿ@ÉÿHÉÿb?gradient_tape/model/batch_normalization_28/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É–@É–HÉ–b?gradient_tape/model/batch_normalization_24/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É–@É–HÉ–b?gradient_tape/model/batch_normalization_25/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É–@É–HÉ–b?gradient_tape/model/batch_normalization_31/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É»@É»HÉ»b?gradient_tape/model/batch_normalization_18/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É»@É»HÉ»b?gradient_tape/model/batch_normalization_22/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É»@É»HÉ»b?gradient_tape/model/batch_normalization_30/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2 8É∏@É∏HÉ∏b?gradient_tape/model/batch_normalization_19/FusedBatchNormGradV3hu  »B
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Çê@ÇêHÇêb-model/batch_normalization_45/FusedBatchNormV3hu  »B
à
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç¯@Ç¯HÇ¯bmodel/add_13/addhuZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8ÇË@ÇËHÇËb-model/batch_normalization_36/FusedBatchNormV3hu  »B
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8É¿@É¿HÉ¿b-model/batch_normalization_48/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É∞@É∞HÉ∞b%gradient_tape/model/re_lu_48/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É∞@É∞HÉ∞b$gradient_tape/model/re_lu_8/ReluGradhuZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8Ç∞@Ç∞HÇ∞b-model/batch_normalization_42/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É†@É†HÉ†b%gradient_tape/model/re_lu_39/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É†@É†HÉ†b$gradient_tape/model/re_lu_6/ReluGradhuZUÖB
´
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2Ä8É†@É†HÉ†b-model/batch_normalization_39/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Éê@ÉêHÉêb%gradient_tape/model/re_lu_12/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Éê@ÉêHÉêb%gradient_tape/model/re_lu_14/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Éê@ÉêHÉêb%gradient_tape/model/re_lu_15/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Çê@ÇêHÇêb%gradient_tape/model/re_lu_45/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Çê@ÇêHÇêb$gradient_tape/model/re_lu_9/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Çà@ÇàHÇàb%gradient_tape/model/re_lu_11/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Çà@ÇàHÇàb%gradient_tape/model/re_lu_36/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Çà@ÇàHÇàb$gradient_tape/model/re_lu_5/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÉÄ@ÉÄHÉÄb%gradient_tape/model/re_lu_42/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÇÄ@ÇÄHÇÄb$gradient_tape/model/re_lu_2/ReluGradhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÇÄ@ÇÄHÇÄb$gradient_tape/model/re_lu_3/ReluGradhuZUÖB
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÇÄ@ÇÄHÇÄbAdam/gradients/AddN_1huZUÖB
Ë
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É¯@É¯HÉ¯b"gradient_tape/model/re_lu/ReluGradhuZUÖB
à
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç¯@Ç¯HÇ¯bmodel/add_14/addhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç¯@Ç¯HÇ¯b$gradient_tape/model/re_lu_1/ReluGradhuZUÖB
à
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÇË@ÇËHÇËbmodel/add_11/addhuZUÖB
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2Äb8Ç–@Ç–HÇ–Xb8gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropInputh
à
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É»@É»HÉ»bmodel/add_12/addhuZUÖB
à
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç»@Ç»HÇ»bmodel/add_10/addhuZUÖB
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç»@Ç»HÇ»bAdam/gradients/AddN_2huZUÖB
ß
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8É∏@É∏HÉ∏bAdam/gradients/AddNhuZUÖB
™
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∏@Ç∏HÇ∏bAdam/gradients/AddN_14huZUÖB
©
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∏@Ç∏HÇ∏bAdam/gradients/AddN_3huZUÖB
ç
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2Äb8É‡@É‡HÉ‡Xb7gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropInputhu  »A
â>
©=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)Ù Ä¿*Ä2)8É¿@É¿HÉ¿Xb9gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropFilterh
â>
©=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)Ù Ä¿*Ä2)8Ç®@Ç®HÇ®Xb9gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropFilterh
»
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params) ÄÄ*Ä2¿8Éò@ÉòHÉòPXb8gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropInputh
∏
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)PÄ*2¿8Çà@ÇàHÇàXbmodel/conv2d_40/Conv2Dhu  HB
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18Ç–@Ç–HÇ–Xb8gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18Ç–@Ç–HÇ–Xb8gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18Ç–@Ç–HÇ–Xb8gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18Ç–@Ç–HÇ–Xb8gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)ˇ ÄÄ*Ä2Ä18Ç»@Ç»HÇ»Xb8gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropInputh
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2Äb8Ç¿@Ç¿HÇ¿Xb8gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropInputh
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2Äb8Ç®@Ç®HÇ®Xb8gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropInputh
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2Äb8Ç†@Ç†HÇ†Xb8gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropInputh
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äb8Çò@ÇòHÇòXbmodel/conv2d_24/Conv2DhuZUÖB
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äb8Çê@ÇêHÇêXbmodel/conv2d_21/Conv2DhuZUÖB
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äb8ÇÄ@ÇÄHÇÄXbmodel/conv2d_27/Conv2DhuZUÖB
∏
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)PÄ*2¿8Å¯@Å¯HÅ¯Xbmodel/conv2d_37/Conv2Dhu  HB
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äb8Ç@ÇHÇXbmodel/conv2d_30/Conv2DhuZUÖB
∏
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)PÄ*2¿8Çÿ@ÇÿHÇÿXbmodel/conv2d_46/Conv2Dhu  HB
∏
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)PÄ*2¿8Ç»@Ç»HÇ»Xbmodel/conv2d_43/Conv2Dhu  HB
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äb8Ç∏@Ç∏HÇ∏Xbmodel/conv2d_18/Conv2DhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅbmodel/re_lu_1/ReluhuZUÖB
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)Â ÄÄ*Ä2ê8Çê@ÇêHÇêPXbmodel/conv2d_33/Conv2Dh
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2¿8Ç–@Ç–HÇ–Xbmodel/conv2d_34/Conv2DhuZUÖB
»
ävoid cutlass::Kernel<cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6::Params)∏ Ä¿*Ä2¿8Çê@ÇêHÇêXbmodel/conv2d_44/Conv2Dh
»
ävoid cutlass::Kernel<cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6::Params)∏ Ä¿*Ä2¿8Çê@ÇêHÇêXbmodel/conv2d_47/Conv2Dh
»
ävoid cutlass::Kernel<cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6::Params)∏ Ä¿*Ä2¿8Çà@ÇàHÇàXbmodel/conv2d_35/Conv2Dh
»
ävoid cutlass::Kernel<cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6::Params)∏ Ä¿*Ä2¿8Çà@ÇàHÇàXbmodel/conv2d_38/Conv2Dh
»
ävoid cutlass::Kernel<cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_analytic_tf32_128x64_16x6::Params)∏ Ä¿*Ä2¿8ÅÄ@ÅÄHÅÄXbmodel/conv2d_41/Conv2Dh
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Ç‡@Å»HÅòXb9gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropFilterhu  »B
ü
ﬂvoid precomputed_convolve_sgemm<float, 1024, 5, 5, 4, 3, 3, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)@Ä$*2Äà8Çÿ@ÇÿHÇÿXbmodel/conv2d_2/Conv2DhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å–@Å–HÅ–bmodel/re_lu_9/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç»@Ç»HÇ»bmodel/re_lu_14/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç¿@Ç¿HÇ¿bmodel/re_lu_45/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å¿@Å¿HÅ¿bmodel/re_lu_48/ReluhuZUÖB
Í
ëvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä2{8Ç∏@Ç∏HÇ∏b4gradient_tape/model/global_average_pooling2d/truedivhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∏@Ç∏HÇ∏bmodel/re_lu_12/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∏@Ç∏HÇ∏bmodel/re_lu_2/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∏@Ç∏HÇ∏bmodel/re_lu_5/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å∏@Å∏HÅ∏bmodel/re_lu_39/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∞@Ç∞HÇ∞bmodel/re_lu_11/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∞@Ç∞HÇ∞bmodel/re_lu_6/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç∞@Ç∞HÇ∞bmodel/re_lu_8/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å∞@Å∞HÅ∞bmodel/re_lu_15/ReluhuZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å∞@Å∞HÅ∞bmodel/re_lu_3/ReluhuZUÖB
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ç®@Ç®HÇ®Xb9gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropFilterhu  »B
ç
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Äƒ8Ç®@Ç®HÇ®b;model/re_lu_48/Relu-0-0-TransposeNCHWToNHWC-LayoutOptimizerhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç†@Ç†HÇ†bmodel/re_lu_42/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å†@Å†HÅ†bmodel/re_lu_36/ReluhuZUÖB
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å†@Å†HÅ†Xb9gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropFilterhu  »B
‘
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Åò@ÅòHÅòbmodel/re_lu/ReluhuZUÖB
ù
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Äƒ8Åò@ÅòHÅòbKgradient_tape/model/re_lu_48/ReluGrad-0-TransposeNHWCToNCHW-LayoutOptimizerhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Åê@ÅêHÅêXbmodel/conv2d_15/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Åê@ÅêHÅêXbmodel/conv2d_9/Conv2Dhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Çà@Å¿HÅ»Xb9gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Åà@Ä¿HÅ»Xb9gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Åà@Å¿HÄ»Xb9gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Åà@Å¿HÄ»Xb9gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropFilterhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Åà@ÅàHÅàXbmodel/conv2d_3/Conv2Dhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÇÄ@ÇÄHÇÄXb9gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÇÄ@ÇÄHÇÄXb9gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8ÇÄ@ÇÄHÇÄXb8gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÇÄ@ÇÄHÇÄXb8gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅÄ@ÅÄHÅÄXb9gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropFilterhu  »B
Í
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8ÅÄ@ÅÄHÅÄXb6gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilterhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8ÅÄ@ÅÄHÅÄXbmodel/conv2d_12/Conv2Dhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ç¯@Ç¯HÇ¯Xb9gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Ç¯@Ç¯HÇ¯Xb9gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å¯@Å¯HÅ¯Xb9gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å¯@Å¯HÅ¯Xb9gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Å¯@Å¯HÅ¯Xb8gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Å¯@Å¯HÅ¯Xb9gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å¯@Å¯HÅ¯Xb8gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ç@ÇHÇXb9gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ç@ÇHÇXb8gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXb8gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXb9gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropFilterhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8Å@ÅHÅXbmodel/conv2d_6/Conv2Dhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXb9gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2† 8ÅË@ÅËHÅËXb8gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)† Ä¿*Ä2¿8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)† Ä¿*Ä2¿8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)† Ä¿*Ä2¿8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)† Ä¿*Ä2¿8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropInputh
ä
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)† Ä¿*Ä2¿8Ç¯@Ç¯HÇ¯Xb8gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropInputh
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8Åò@ÅòHÅòb-model/batch_normalization_31/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8Åê@ÅêHÅêb-model/batch_normalization_21/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8Çà@ÇàHÇàb-model/batch_normalization_24/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8Åà@ÅàHÅàb-model/batch_normalization_27/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8Åà@ÅàHÅàb-model/batch_normalization_30/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8ÇÄ@ÇÄHÇÄb-model/batch_normalization_18/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8ÅÄ@ÅÄHÅÄb-model/batch_normalization_22/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8ÅÄ@ÅÄHÅÄb-model/batch_normalization_25/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8ÅÄ@ÅÄHÅÄb-model/batch_normalization_28/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2 8Å@ÅHÅb-model/batch_normalization_19/FusedBatchNormV3hu  »B
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)Â ÄÄ*Ä2ê8Å–@Å–HÅ–PXbmodel/conv2d_48/Conv2Dh
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)Â ÄÄ*Ä2ê8Å¿@Å¿HÅ¿PXbmodel/conv2d_45/Conv2Dh
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)Â ÄÄ*Ä2ê8Å∞@Å∞HÅ∞PXbmodel/conv2d_36/Conv2Dh
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)Â ÄÄ*Ä2ê8Å®@Å®HÅ®PXbmodel/conv2d_42/Conv2Dh
¶
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 1, 1, false>, 4>::Params)Â ÄÄ*Ä2ê8Å¯@Å¯HÅ¯PXbmodel/conv2d_39/Conv2Dh
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Åÿ@ÅÿHÅÿb%gradient_tape/model/re_lu_24/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Åÿ@ÅÿHÅÿb%gradient_tape/model/re_lu_25/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å–@Å–HÅ–b%gradient_tape/model/re_lu_19/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å–@Å–HÅ–b%gradient_tape/model/re_lu_21/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ç»@Ç»HÇ»b%gradient_tape/model/re_lu_27/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å»@Å»HÅ»b%gradient_tape/model/re_lu_18/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å»@Å»HÅ»b%gradient_tape/model/re_lu_22/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å»@Å»HÅ»b%gradient_tape/model/re_lu_28/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å∏@Å∏HÅ∏b%gradient_tape/model/re_lu_31/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å®@Å®HÅ®b%gradient_tape/model/re_lu_30/ReluGradhuZUÖB
Ñ
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*Ä2§8Çò@ÅêHÅà
Xbmodel/conv2d/Conv2Dhu  »B
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2ê8ÇÄ@ÇÄHÇÄXb8gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2ê8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2ê8ÅÄ@ÅÄHÅÄXb8gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2ê8Å¯
@Å¯
HÅ¯
Xb8gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropInputhu  »A
é
*ampere_scudnn_128x64_stridedB_medium_nn_v1ÄÄÄ*Ä2ê8Å¯
@Å¯
HÅ¯
Xb8gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropInputhu  »A
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2¿8Å»
@Å»
HÅ»
Xb8gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropInputh
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2¿8Å»
@Å»
HÅ»
Xb8gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropInputh
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2¿8Å∏
@Å∏
HÅ∏
Xb8gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropInputh
å
¨void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x128_16x4_unity_stride::Params)ˆ ÄÄ*Ä2¿8Å∏
@Å∏
HÅ∏
Xb8gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropInputh
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Å®
@Å®
HÅ®
b?gradient_tape/model/batch_normalization_34/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Å®
@Å®
HÅ®
b?gradient_tape/model/batch_normalization_40/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Å†
@Å†
HÅ†
b?gradient_tape/model/batch_normalization_46/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åò
@Åò
HÅò
b?gradient_tape/model/batch_normalization_37/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åò
@Åò
HÅò
b?gradient_tape/model/batch_normalization_38/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åò
@Åò
HÅò
b?gradient_tape/model/batch_normalization_41/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åê
@Åê
HÅê
b?gradient_tape/model/batch_normalization_35/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åê
@Åê
HÅê
b?gradient_tape/model/batch_normalization_44/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åà
@Åà
HÅà
b?gradient_tape/model/batch_normalization_43/FusedBatchNormGradV3hu  »B
Ê
ˇvoid cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float) ê*Ä2@8Åà
@Åà
HÅà
b?gradient_tape/model/batch_normalization_47/FusedBatchNormGradV3hu  »B
ß
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*Ä2§8Åà
@Åà
HÅà
Xb6gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilterhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅbmodel/re_lu_19/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å‡@Å‡HÅ‡bmodel/re_lu_21/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å‡@Å‡HÅ‡bmodel/re_lu_22/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å‡@Å‡HÅ‡bmodel/re_lu_28/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å‡@Å‡HÅ‡bmodel/re_lu_30/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Åÿ@ÅÿHÅÿbmodel/re_lu_25/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Åÿ@ÅÿHÅÿbmodel/re_lu_27/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Åÿ@ÅÿHÅÿbmodel/re_lu_31/ReluhuZUÖB
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Åÿ@ÄËHÅXb9gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Åÿ@ÅËHÄXb9gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropFilterhu  »B
 
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Åÿ@ÅÿHÅÿXbmodel/conv2d_31/Conv2Dhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Äÿ@ÄÿHÄÿbmodel/re_lu_18/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Äÿ@ÄÿHÄÿbmodel/re_lu_24/ReluhuZUÖB
‡
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)#*Ä2{8·◊@·◊H·◊b8gradient_tape/model/global_average_pooling2d/BroadcastTohuZUÖB
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å–@ÄËHÅËXb9gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å–@Ä‡HÅXb9gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropFilterhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å–@Å–HÅ–Xb9gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropFilterhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å–@Å–HÅ–Xbmodel/conv2d_31/Conv2Dhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å–@Å–HÅ–Xb8gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å–@Å–HÅ–Xb8gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å–@Å–HÅ–Xb8gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropInputhu  »B
 
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å–@Å–HÅ–Xbmodel/conv2d_22/Conv2Dhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å»@Ä‡HÅËXb9gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xb8gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropInputhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xb9gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropFilterhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xbmodel/conv2d_19/Conv2Dhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xbmodel/conv2d_22/Conv2Dhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xbmodel/conv2d_28/Conv2Dhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xb8gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xb8gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xb8gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropInputhu  »B
 
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xbmodel/conv2d_19/Conv2Dhu  »B
 
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xbmodel/conv2d_25/Conv2Dhu  »B
 
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å»@Å»HÅ»Xbmodel/conv2d_28/Conv2Dhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Ä»@Ä»HÄ»Xb9gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropFilterhu  »B
 
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Ä»@Ä»HÄ»Xbmodel/conv2d_25/Conv2Dhu  »B
Œ
Évoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, tensorflow::functor::Sum<float> >::Policy600, float*, tensorflow::TransformOutputIterator<float, float, tensorflow::functor::DividesBy<float, float>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, tensorflow::functor::Sum<float>, float>(float*, tensorflow::TransformOutputIterator<float, float, tensorflow::functor::DividesBy<float, float>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, tensorflow::functor::Sum<float>, float)0*Ä2Ä@8Å¿@Å¿HÅ¿b#model/global_average_pooling2d/Meanhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb8gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropInputhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb9gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb8gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb8gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb8gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb8gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å¿@Å¿HÅ¿Xb8gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Ä¿@Ä¿HÄ¿Xb8gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Ä∏@Ä∏HÄ∏Xb8gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å∞@Å∞HÅ∞Xb8gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å∞@Å∞HÅ∞Xb8gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropInputhu  »B
Ì
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å∞@Å∞HÅ∞Xb9gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å∞@Å∞HÅ∞Xb8gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Å∞@Å∞HÅ∞Xb8gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2à 8Ä®@Ä®HÄ®Xb8gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropInputhu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÅÄ@ÅÄHÅÄb%gradient_tape/model/re_lu_37/ReluGradhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8ÅÄ@ÅÄHÅÄb-model/batch_normalization_47/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å¯@Å¯HÅ¯b%gradient_tape/model/re_lu_41/ReluGradhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8Å¯@Å¯HÅ¯b-model/batch_normalization_44/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä¯@Ä¯HÄ¯b%gradient_tape/model/re_lu_34/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä¯@Ä¯HÄ¯b%gradient_tape/model/re_lu_43/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä¯@Ä¯HÄ¯b%gradient_tape/model/re_lu_47/ReluGradhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8Ä¯@Ä¯HÄ¯b-model/batch_normalization_46/FusedBatchNormV3hu  »B
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅb%gradient_tape/model/re_lu_35/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅb%gradient_tape/model/re_lu_38/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅb%gradient_tape/model/re_lu_40/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅb%gradient_tape/model/re_lu_44/ReluGradhuZUÖB
Î
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅb%gradient_tape/model/re_lu_46/ReluGradhuZUÖB
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8Å@ÅHÅb-model/batch_normalization_35/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8Å@ÅHÅb-model/batch_normalization_38/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8Ä@ÄHÄb-model/batch_normalization_34/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8Ä@ÄHÄb-model/batch_normalization_41/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8ÅË@ÅËHÅËb-model/batch_normalization_40/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8ÄË@ÄËHÄËb-model/batch_normalization_37/FusedBatchNormV3hu  »B
™
’void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float) ê*Ä2@8ÄË@ÄËHÄËb-model/batch_normalization_43/FusedBatchNormV3hu  »B
Ø
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä`*Ä2¿8Å¿@Å¿HÅ¿b\gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizerhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å®@Å®HÅ®bmodel/re_lu_37/ReluhuZUÖB
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å®@Å®HÅ®Xb8gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropInputhu  »B
…
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä†@Ä†HÄ†Xbmodel/conv2d_35/Conv2Dhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅÄ@ÅÄHÅÄXb9gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropFilterhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8ÄÄ@ÄÄHÄÄbmodel/re_lu_47/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å¯@Å¯HÅ¯bmodel/re_lu_43/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å¯@Å¯HÅ¯bmodel/re_lu_46/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä¯@Ä¯HÄ¯bmodel/re_lu_35/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä¯@Ä¯HÄ¯bmodel/re_lu_38/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä¯@Ä¯HÄ¯bmodel/re_lu_40/ReluhuZUÖB
…
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä¯@Ä¯HÄ¯Xbmodel/conv2d_47/Conv2Dhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅbmodel/re_lu_34/ReluhuZUÖB
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Å@ÅHÅbmodel/re_lu_41/ReluhuZUÖB
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXb9gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXb9gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXb8gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropInputhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXbmodel/conv2d_36/Conv2Dhu  »B
…
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å@ÅHÅXbmodel/conv2d_41/Conv2Dhu  »B
◊
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2{8Ä@ÄHÄbmodel/re_lu_44/ReluhuZUÖB
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXb9gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropFilterhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXbmodel/conv2d_35/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXbmodel/conv2d_38/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXbmodel/conv2d_47/Conv2Dhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXb8gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXb8gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXb8gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropInputhu  »B
…
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä@ÄHÄXbmodel/conv2d_38/Conv2Dhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXb9gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXb8gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXb9gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropFilterhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXbmodel/conv2d_39/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXbmodel/conv2d_41/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXbmodel/conv2d_45/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXbmodel/conv2d_48/Conv2Dhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÅË@ÅËHÅËXb8gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb8gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb9gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb8gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb9gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropFilterhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb9gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropFilterhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb8gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropInputhu  »B
Ï
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb9gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropFilterhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXbmodel/conv2d_42/Conv2Dhu  »B
…
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXbmodel/conv2d_44/Conv2Dhu  »B
Î
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXb8gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropInputhu  »B
…
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8ÄË@ÄËHÄËXbmodel/conv2d_44/Conv2Dhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Å‡@Å‡HÅ‡Xb8gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Ä‡@Ä‡HÄ‡Xb8gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Åÿ@ÅÿHÅÿXb8gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropInputhu  »B
Î
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2b 8Äÿ@ÄÿHÄÿXb8gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropInputhu  »B

ëvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, long)=*Ä28Ä∏@Ä∏HÄ∏b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
º
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x4_nn_align1>(cutlass_80_tensorop_s1688gemm_64x64_32x4_nn_align1::Params)® ÄÄ*@28ÄÄ@ÄÄHÄÄXbmodel/dense/MatMulh
§
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*Ä2§8Äp@ÄpHÄpXb6gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilterhu  »B
«
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x4_nt_align1>(cutlass_80_tensorop_s1688gemm_64x64_32x4_nt_align1::Params)® ÄÄ*@28Ä`@Ä`HÄ`b"gradient_tape/model/dense/MatMul_1h
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28ÄX@ÄXHÄXXbmodel/conv2d_34/Conv2DhuZUÖB
Ÿ
ˆvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)@ Äà*Ä28ÅP@ÅPHÅPPXb9gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropFilterhu≥™&B
Ÿ
ˆvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)@ Äà*Ä28ÄP@ÄPHÄPPXb9gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropFilterhu≥™&B
Ÿ
ˆvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)@ Äà*Ä28ÄP@ÄPHÄPPXb9gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropFilterhu≥™&B
Ÿ
ˆvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, true, 16, xmma_new::Col, 16, 128> >, true, 4>::Params)@ Äà*Ä28ÄH@ÄHHÄHPXb9gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropFilterhu≥™&B
Î
èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorReshapingOp<Eigen::IndexList<int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> >, Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorReshapingOp<Eigen::IndexList<int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> >, Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, long)@*Ä28Ä@@Ä@HÄ@b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
^
ampere_sgemm_128x128_tnvÄÑ*Ä28Ä0@Ä0HÄ0Xb gradient_tape/model/dense/MatMulhuMUB
Â
âvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorReshapingOp<Eigen::IndexList<int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> >, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorReshapingOp<Eigen::IndexList<int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> >, Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const> const, Eigen::GpuDevice>, long)7*Ä28Ä0@Ä0HÄ0b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä(@Ä(HÄ(Xb9gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä(@Ä(HÄ(Xb9gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä(@Ä(HÄ(Xb8gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä(@Ä(HÄ(Xb8gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropFilterhu  »B
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä(@Ä(HÄ(Xb8gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä(@Ä(HÄ(Xb9gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 2@8Ä(@Ä(HÄ(Xb9gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä(@Ä(HÄ(Xb8gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropInputhu  »B
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2$8Ä(@Ä(HÄ(b&Adam/Adam/update_104/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2$8Ä(@Ä(HÄ(b&Adam/Adam/update_123/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Å @Å HÅ b%Adam/Adam/update_69/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2$8Å @Å HÅ b&Adam/Adam/update_132/ResourceApplyAdamhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Å @Å HÅ Xbmodel/conv2d_37/Conv2DhuZUÖB
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropInputhu  »B
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb7gradient_tape/model/conv2d_5/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb7gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb7gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä @Ä HÄ Xb7gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropInputhu  »B
¬
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä @Ä HÄ Xb6gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä @Ä HÄ Xb9gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä @Ä HÄ Xb9gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä @Ä HÄ Xb8gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä @Ä HÄ Xb9gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropFilterhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä @Ä HÄ Xbmodel/conv2d_28/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä @Ä HÄ Xbmodel/conv2d_41/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä @Ä HÄ Xbmodel/conv2d_36/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä @Ä HÄ Xbmodel/conv2d_39/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä @Ä HÄ Xbmodel/conv2d_42/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä @Ä HÄ Xbmodel/conv2d_45/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä @Ä HÄ Xbmodel/conv2d_48/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä @Ä HÄ Xbmodel/conv2d_33/Conv2Dhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropInputhu  »B
á
´void tensorflow::(anonymous namespace)::DynamicStitchKernel<int>(int, int, tensorflow::GpuDeviceArrayStruct<int, 8>, tensorflow::GpuDeviceArrayStruct<int const*, 8>, int*)*Ä28Ä @Ä HÄ b:gradient_tape/model/global_average_pooling2d/DynamicStitchhuZUÖB
˘
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b"Adam/Adam/update/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b$Adam/Adam/update_1/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_100/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_102/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_105/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_109/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_11/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_119/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_12/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_121/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_124/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_127/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_128/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_13/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_130/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_131/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_133/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_137/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_139/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_142/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_145/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_148/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_16/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_17/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_19/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_21/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_22/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_25/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_28/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b$Adam/Adam/update_3/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_30/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_31/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_33/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_37/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_39/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_40/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_42/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_43/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_46/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_49/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b$Adam/Adam/update_5/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_51/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_58/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_64/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_70/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_73/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_76/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_79/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_82/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_85/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_88/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_91/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_94/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_97/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_36/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_63/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_72/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_78/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_81/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_87/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_90/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_96/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_101/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b%Adam/Adam/update_59/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2	8Ä @Ä HÄ b%Adam/Adam/update_75/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2	8Ä @Ä HÄ b%Adam/Adam/update_84/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2	8Ä @Ä HÄ b%Adam/Adam/update_93/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_108/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_117/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_120/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_126/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_135/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_138/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä @Ä HÄ b&Adam/Adam/update_144/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2 8Ä @Ä HÄ b&Adam/Adam/update_107/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2$8Ä @Ä HÄ b&Adam/Adam/update_114/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2$8Ä @Ä HÄ b&Adam/Adam/update_141/ResourceApplyAdamhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb8gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb9gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb8gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb8gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbmodel/conv2d_20/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbmodel/conv2d_17/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä @Ä HÄ Xb9gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb9gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropFilterhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbmodel/conv2d_42/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbmodel/conv2d_45/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xbmodel/conv2d_46/Conv2DhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2 8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2 8Ä @Ä HÄ Xbmodel/conv2d_33/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb9gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb8gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xbmodel/conv2d_35/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xbmodel/conv2d_47/Conv2DhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Å@ÅHÅb&Adam/Adam/update_106/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Å@ÅHÅb&Adam/Adam/update_110/ResourceApplyAdamhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Å@ÅHÅXb8gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Å@ÅHÅXb8gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropInputhuZUÖB
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb7gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropInputhu  »B
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb8gradient_tape/model/conv2d_11/Conv2D/Conv2DBackpropInputhu  »B
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb8gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropInputhu  »B
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb8gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
û
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb8gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb7gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb7gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb7gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä2≈8Ä@ÄHÄXb7gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInputhu  »B
ì
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb,categorical_crossentropy/weighted_loss/valuehuZUÖB
˝
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/PowhuZUÖB
ò
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOphuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_2huZUÖB
…
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, int) *Ä28Ä@ÄHÄbLgradient_tape/categorical_crossentropy/softmax_cross_entropy_with_logits/mulhuZUÖB
à
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄbmodel/dense/BiasAddhuZUÖB
ˇ	
£	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)(*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
≈
Èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)**Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
Û
…void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long, long>, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long, long>, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/addhuZUÖB
≥
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbArgMaxhuZUÖB
µ
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbArgMax_1huZUÖB
≠
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long) *Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb8gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropFilterhu  »B
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb8gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb9gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropFilterhu  »B
ƒ
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb8gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb9gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb9gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropFilterhu  »B
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)#* 28Ä@ÄHÄXb9gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropFilterhu  »B
‡
Çvoid nchwToFoldedNhwcKernel<float, float, float, true, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä!* 2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropInputhu  »B
·
Çvoid nchwToFoldedNhwcKernel<float, float, float, true, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä!* 2Ä8Ä@ÄHÄXb8gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
≈
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXbmodel/conv2d_3/Conv2Dhu  »B
≈
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXbmodel/conv2d_6/Conv2Dhu  »B
≈
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXbmodel/conv2d_9/Conv2Dhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropInputhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXbmodel/conv2d_19/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXbmodel/conv2d_22/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXbmodel/conv2d_25/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXbmodel/conv2d_31/Conv2Dhu  »B
È
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä@ÄHÄXb8gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropInputhu  »B
È
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä@ÄHÄXb8gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropInputhu  »B
È
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä@ÄHÄXb8gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropInputhu  »B
È
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä@ÄHÄXb8gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropInputhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXbmodel/conv2d_35/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXbmodel/conv2d_38/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXbmodel/conv2d_44/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXbmodel/conv2d_47/Conv2Dhu  »B
«
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä@ÄHÄXbmodel/conv2d_17/Conv2Dhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_21/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropInputhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
Ë
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
Ë
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropFilterhu  »B
Ë
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb9gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb9gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb9gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb9gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb9gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb9gradient_tape/model/conv2d_35/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb9gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb9gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb9gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropFilterhu  »B
È
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb9gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropFilterhu  »B
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_10/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_103/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_112/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_113/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_115/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_116/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_118/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_122/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_125/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_134/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_136/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_14/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_140/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_143/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_146/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_147/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_15/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb$Adam/Adam/update_2/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_20/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_23/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_24/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_26/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_29/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_32/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_34/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_35/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_38/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb$Adam/Adam/update_4/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_41/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_44/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_47/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_48/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_50/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_52/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_54/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_55/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_57/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb$Adam/Adam/update_6/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_61/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_62/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_65/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_67/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_68/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb$Adam/Adam/update_7/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_71/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_74/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_77/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_80/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_83/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_86/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_89/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb$Adam/Adam/update_9/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_92/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_95/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_98/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_99/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_53/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_18/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_27/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_45/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb$Adam/Adam/update_8/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb%Adam/Adam/update_60/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2	8Ä@ÄHÄb%Adam/Adam/update_56/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä2	8Ä@ÄHÄb%Adam/Adam/update_66/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_111/ResourceApplyAdamhuZUÖB
˝
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*Ä28Ä@ÄHÄb&Adam/Adam/update_129/ResourceApplyAdamhuZUÖB
Î
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄbSum_2hu  »B
ö
œvoid tensorflow::functor::ColumnReduceMax16ColumnsKernel<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)Ä!* 28Ä@ÄHÄb'gradient_tape/model/dense/BiasAdd/Sum_1hu  »B
ˇ
≈void tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>(cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, int, int, cub::Sum, std::iterator_traits<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long> >::value_type)*Ä28Ä@ÄHÄbmodel/activation/Softmaxhu  »B
›
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type) *Ä28Ä@ÄHÄbmodel/activation/Softmaxhu  »B
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_11/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_11/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_14/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropInputhuZUÖB
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropInputhuZUÖB
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_5/Conv2D/Conv2DBackpropFilterhuZUÖB
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_5/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropFilterhuZUÖB
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropFilterhuZUÖB
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInputhuZUÖB
º
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_1/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_10/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_11/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_13/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_14/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_16/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_4/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_5/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_7/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_8/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_18/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_18/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_15/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropFilterhuZUÖB
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropFilterhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_12/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_15/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_3/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_6/Conv2DhuZUÖB
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_9/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropFilterhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_23/Conv2D/Conv2DBackpropFilterhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_24/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_26/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_27/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_29/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_30/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_32/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_21/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_23/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_24/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_26/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_27/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_29/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_30/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_32/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_17/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_34/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb9gradient_tape/model/conv2d_22/Conv2D/Conv2DBackpropFilterhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb9gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb8gradient_tape/model/conv2d_25/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb9gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb8gradient_tape/model/conv2d_28/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb9gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXb8gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXbmodel/conv2d_19/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXbmodel/conv2d_22/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXbmodel/conv2d_25/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXbmodel/conv2d_28/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2	8Ä@ÄHÄXbmodel/conv2d_31/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_37/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_40/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_43/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropInputhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_46/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb9gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_36/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_39/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_40/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_43/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXbmodel/conv2d_48/Conv2DhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2 8Ä@ÄHÄXb9gradient_tape/model/conv2d_33/Conv2D/Conv2DBackpropFilterhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb9gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb8gradient_tape/model/conv2d_38/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb9gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb8gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb9gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb8gradient_tape/model/conv2d_44/Conv2D/Conv2DBackpropInputhuZUÖB
‚
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb9gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropFilterhuZUÖB
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb8gradient_tape/model/conv2d_47/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXbmodel/conv2d_38/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXbmodel/conv2d_41/Conv2DhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXbmodel/conv2d_44/Conv2DhuZUÖB
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_1/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_10/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_11/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_12/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_2/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_3/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_36/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_45/Conv2D/Conv2DBackpropInputhu  »B
ü
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_5/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_6/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInputhu  »B
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*Ä28Ä@ÄHÄXb7gradient_tape/model/conv2d_9/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_39/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_42/Conv2D/Conv2DBackpropInputhu  »B
ù
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams) *Ä28Ä@ÄHÄXb8gradient_tape/model/conv2d_48/Conv2D/Conv2DBackpropInputhu  »B
⁄
≥void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<long>, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::equal_to<long>, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbEqualhuZUÖB
Ì
¡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
LogicalAndhuZUÖB
‡
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄb;gradient_tape/categorical_crossentropy/weighted_loss/Tile_1huZUÖB
Ò
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
div_no_nanhuZUÖB
Û
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbdiv_no_nan_1huZUÖB
¨
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbEgradient_tape/categorical_crossentropy/weighted_loss/value/div_no_nanhuZUÖB
ˇ
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
Adam/Pow_1huZUÖB
Ä
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbMulhuZUÖB
˝
’void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbCast_1huZUÖB
˘
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbCasthuZUÖB
˚
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbCast_2huZUÖB
≠
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb8categorical_crossentropy/weighted_loss/num_elements/CasthuZUÖB
¶
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb1gradient_tape/model/global_average_pooling2d/CasthuZUÖB
Ç
’void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/Cast_1huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_1huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_3huZUÖB
ò
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/Adam/AssignAddVariableOphuZUÖB
ê
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_4huZUÖB
˜
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ä
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*28Ä@ÄHÄXbmodel/conv2d_2/Conv2DhuGU@
ã
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2@8Ä@ÄHÄXbmodel/conv2d_11/Conv2DhuGU@
ã
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2@8Ä@ÄHÄXbmodel/conv2d_14/Conv2DhuGU@
ã
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2@8Ä@ÄHÄXbmodel/conv2d_18/Conv2DhuGU@
ä
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2@8Ä@ÄHÄXbmodel/conv2d_5/Conv2DhuGU@
ä
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2@8Ä@ÄHÄXbmodel/conv2d_8/Conv2DhuGU@
å
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2Ä8Ä@ÄHÄXbmodel/conv2d_21/Conv2DhuGU@
å
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2Ä8Ä@ÄHÄXbmodel/conv2d_24/Conv2DhuGU@
å
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2Ä8Ä@ÄHÄXbmodel/conv2d_27/Conv2DhuGU@
å
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2Ä8Ä@ÄHÄXbmodel/conv2d_30/Conv2DhuGU@
å
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*2Ä8Ä@ÄHÄXbmodel/conv2d_34/Conv2DhuGU@
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXbmodel/conv2d_12/Conv2Dhu  »B
∆
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä28Ä@ÄHÄXbmodel/conv2d_15/Conv2Dhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_19/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2 8Ä@ÄHÄXb8gradient_tape/model/conv2d_31/Conv2D/Conv2DBackpropInputhu  »B
È
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2Ä8Ä@ÄHÄXb8gradient_tape/model/conv2d_20/Conv2D/Conv2DBackpropInputhu  »B
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float) Ä!*Ä2@8Ä@ÄHÄXb8gradient_tape/model/conv2d_41/Conv2D/Conv2DBackpropInputhu  »B
À
ëvoid tensorflow::(anonymous namespace)::GenerateNormalizedProb<float, float, 4>(float const*, float const*, float const*, float*, int, int, bool) *Ä28Ä@ÄHÄbmodel/activation/Softmaxhu  »B
ê
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄb*categorical_crossentropy/weighted_loss/Sumhu  »B
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb6gradient_tape/model/conv2d/Conv2D/Conv2DBackpropFilterhuZUÖB