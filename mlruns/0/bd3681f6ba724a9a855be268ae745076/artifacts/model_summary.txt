Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 128, 16) 432         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 128, 16) 64          conv2d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 128, 128, 16) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 128, 128, 16) 64          re_lu[0][0]                      
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 128, 128, 16) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 128, 16) 256         re_lu_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 128, 128, 16) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 128, 16) 2304        re_lu_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 128, 128, 16) 64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 128, 128, 16) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 128, 64) 1024        re_lu[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 64) 1024        re_lu_3[0][0]                    
__________________________________________________________________________________________________
add (Add)                       (None, 128, 128, 64) 0           conv2d_1[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         add[0][0]                        
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 128, 16) 1024        re_lu_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 128, 128, 16) 64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 128, 128, 16) 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 128, 128, 16) 2304        re_lu_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 128, 128, 16) 64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 128, 128, 16) 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 128, 128, 64) 1024        re_lu_6[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_7[0][0]                   
                                                                 add[0][0]                        
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         add_1[0][0]                      
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 128, 128, 64) 256         re_lu_7[0][0]                    
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 64, 64, 32)   2048        re_lu_8[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 64, 64, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 64, 64, 32)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 64, 32)   9216        re_lu_9[0][0]                    
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 64, 64, 32)   128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 64, 64, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 64, 64, 128)  8192        re_lu_7[0][0]                    
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 64, 128)  4096        re_lu_10[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 64, 64, 128)  0           conv2d_8[0][0]                   
                                                                 conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         add_2[0][0]                      
__________________________________________________________________________________________________
re_lu_11 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 64, 64, 32)   4096        re_lu_11[0][0]                   
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 64, 64, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
re_lu_12 (ReLU)                 (None, 64, 64, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 64, 32)   9216        re_lu_12[0][0]                   
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 64, 64, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
re_lu_13 (ReLU)                 (None, 64, 64, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 64, 64, 128)  4096        re_lu_13[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 64, 64, 128)  0           conv2d_14[0][0]                  
                                                                 add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         add_3[0][0]                      
__________________________________________________________________________________________________
re_lu_14 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         re_lu_14[0][0]                   
__________________________________________________________________________________________________
re_lu_15 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 64)   8192        re_lu_15[0][0]                   
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
re_lu_16 (ReLU)                 (None, 32, 32, 64)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 64)   36864       re_lu_16[0][0]                   
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
re_lu_17 (ReLU)                 (None, 32, 32, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 256)  32768       re_lu_14[0][0]                   
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 256)  16384       re_lu_17[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 256)  0           conv2d_15[0][0]                  
                                                                 conv2d_18[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 256)  1024        add_4[0][0]                      
__________________________________________________________________________________________________
re_lu_18 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 64)   16384       re_lu_18[0][0]                   
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
re_lu_19 (ReLU)                 (None, 32, 32, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 32, 32, 64)   36864       re_lu_19[0][0]                   
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
re_lu_20 (ReLU)                 (None, 32, 32, 64)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 32, 32, 256)  16384       re_lu_20[0][0]                   
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 256)  0           conv2d_21[0][0]                  
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        add_5[0][0]                      
__________________________________________________________________________________________________
re_lu_21 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 256)          0           re_lu_21[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            514         global_average_pooling2d[0][0]   
__________________________________________________________________________________________________
activation (Activation)         (None, 2)            0           dense[0][0]                      
==================================================================================================
Total params: 220,978
Trainable params: 217,842
Non-trainable params: 3,136
__________________________________________________________________________________________________