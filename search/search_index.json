{"config":{"lang":["fr"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Acceuil"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"make_dataset/","text":"Initialisation du dataset create_train_val_test_datasets ( raw_images , raw_labels , test_size = 0.25 ) Creation of datasets. Create three image datasets (train, validation, and test) given raw_images and raw_labels . The first step is to gather raw_images and raw_labels in a single dataset entity, then shuffle it, this is to ensure that the dataset is already well shuffled before the before using the scikit_learn module train_test_split (for example dataset could be alphabetically sorted before the shuffling). Then dataset passes into train_test_split to first get the images_train and labels_train and an intermediate images_val and labels_val . The intermediate images_val and labels_val is then again split in half to get the actual images_val , labels_val , images_test , labels_test . Parameters: Name Type Description Default raw_images List[pathlib.Path] Full list of the images used for the three datasets. required raw_labels List[str] Full list of the labels used for the three datasets. required test_size Optional[float] Ratio used in the first use of train_test_split . Defaults to split. 0.25 Returns: Type Description Tuple[List[pathlib.Path], List[str], List[pathlib.Path], List[str], List[pathlib.Path], List[str]] Datasets: The three \"datasets\" returned as lists of images, labels. Note Datasets is the alias for the following type. python Datasets = Tuple[ List[Path], List[str], List[Path], List[str], List[Path], List[str] ] Source code in src/make_dataset.py def create_train_val_test_datasets ( raw_images : List [ Path ], raw_labels : List [ str ], test_size : Optional [ float ] = split , ) -> Datasets : \"\"\"Creation of datasets. Create three image datasets (train, validation, and test) given `raw_images` and `raw_labels`. The first step is to gather `raw_images` and `raw_labels` in a single `dataset` entity, then shuffle it, this is to ensure that the dataset is already well shuffled before the before using the `scikit_learn` module `train_test_split` (for example `dataset` could be alphabetically sorted before the shuffling). Then `dataset` passes into `train_test_split` to first get the `images_train` and `labels_train` and an intermediate `images_val` and `labels_val`. The intermediate `images_val` and `labels_val` is then again split in half to get the actual `images_val`, `labels_val`, `images_test`, `labels_test`. Args: raw_images (List[Path]): Full list of the images used for the three datasets. raw_labels (List[str]): Full list of the labels used for the three datasets. test_size (Optional[float], optional): Ratio used in the first use of `train_test_split`. Defaults to split. Returns: Datasets: The three \"datasets\" returned as lists of images, labels. Note: Datasets is the alias for the following type. ```python Datasets = Tuple[ List[Path], List[str], List[Path], List[str], List[Path], List[str] ]``` \"\"\" set_seed ( random_seed ) dataset = list ( zip ( raw_images , raw_labels )) random . shuffle ( dataset ) shuffled_images , shuffled_labels = zip ( * dataset ) images_train , images_val , labels_train , labels_val = train_test_split ( shuffled_images , shuffled_labels , test_size = test_size , random_state = random_seed , ) images_val , images_test , labels_val , labels_test = train_test_split ( images_val , labels_val , test_size = 0.5 , random_state = random_seed ) return ( images_train , labels_train , images_val , labels_val , images_test , labels_test , ) get_files_paths ( root_directory , extension = '.jpg' ) Given an extension, gives a list of files and a list of subdirectories. Starting from root_directory , recursively search all subdirs of root_directory for all files of the given extension . We suppose here that each subdir corresponds to a different class in a classification problem, ie : root_directory | |___ subdir_A (class_A) |___ subdir_B (class_B) |___ ... Parameters: Name Type Description Default root_directory Path Root directory where to start the recursive search. required extension Optional[str] Type of files we want to list during the recursive search. Defaults to \".jpg\". '.jpg' Returns: Type Description Tuple[List[pathlib.Path], List[pathlib.Path]] The list of all files of the given extension, and the list of all the subdirectories. Source code in src/make_dataset.py def get_files_paths ( root_directory : Path , extension : Optional [ str ] = \".jpg\" ) -> Tuple [ List [ Path ], List [ Path ]]: \"\"\"Given an extension, gives a list of files and a list of subdirectories. Starting from `root_directory`, recursively search all subdirs of `root_directory` for all files of the given `extension`. We suppose here that each subdir corresponds to a different class in a classification problem, ie : root_directory | |___ subdir_A (class_A) |___ subdir_B (class_B) |___ ... Args: root_directory (Path): Root directory where to start the recursive search. extension (Optional[str], optional): Type of files we want to list during the recursive search. Defaults to \".jpg\". Returns: The list of all files of the given extension, and the list of all the subdirectories. \"\"\" subdirs = [ subdir for subdir in Path ( root_directory ) . iterdir () if subdir . is_dir ()] logger . info ( f \"Found subfolders : { subdirs } \" ) logger . info ( f \"Searching { extension } files\" ) files_paths = sorted ( image for image in Path ( root_directory ) . glob ( f \"**/* { extension } \" ) if image . is_file () ) num_files = len ( files_paths ) logger . info ( f \"Found { num_files } files\" ) return files_paths , subdirs get_images_paths_and_labels ( images_paths , folders ) Creation of a representation of a dataset as lists (image, label). Given a list of images_paths and a list of folders , create two lists in bijection with each other, meaning to each row (an image path) in the first list corresponds a row (a label) in the second list. Also checks if the labels in the two lists correspond. Parameters: Name Type Description Default images_paths List[pathlib.Path] List containing all the images_paths. required folders List[pathlib.Path] List constaining the folders (labels). required Note The paths given here are the absolute ones, not the relative ones. Be sure to have the rights paths when changing from one workspace to another. Exceptions: Type Description ValueError Class deduced from image_path which isn't in 'folders' list. Note image_path.parent has to be in folders . Otherwise that would mean that the first list images_paths contains more classes than the list folders . Raise an error if so. Returns: Type Description Tuple[List[pathlib.Path], List[str]] The two lists being in bijection image <-> label. Source code in src/make_dataset.py def get_images_paths_and_labels ( images_paths : List [ Path ], folders : List [ Path ] ) -> Tuple [ List [ Path ], List [ str ]]: \"\"\"Creation of a representation of a dataset as lists (image, label). Given a list of `images_paths` and a list of `folders`, create two lists in bijection with each other, meaning to each row (an image path) in the first list corresponds a row (a label) in the second list. Also checks if the labels in the two lists correspond. Args: images_paths (List[Path]): List containing all the images_paths. folders (List[Path]): List constaining the folders (labels). Note: The paths given here are the absolute ones, not the relative ones. Be sure to have the rights paths when changing from one workspace to another. Raises: ValueError: Class deduced from image_path which isn't in 'folders' list. Note: `image_path.parent` has to be in `folders`. Otherwise that would mean that the first list `images_paths` contains more classes than the list `folders`. Raise an error if so. Returns: The two lists being in bijection image <-> label. \"\"\" images = [] labels = [] logger . info ( \"Creating images <-> labels representation.\" ) for image_path in images_paths : filename = image_path . absolute () folder = image_path . parent . name if image_path . parent in folders : images . append ( filename ) labels . append ( folder ) else : raise ValueError ( \"Class deduced from image_path which isn't in 'folders' list.\" ) return images , labels main () Main function. Source code in src/make_dataset.py @app . command () def main () -> None : \"\"\"Main function.\"\"\" files_paths , subdirs = get_files_paths ( raw_dataset_address ) raw_images , raw_labels = get_images_paths_and_labels ( files_paths , subdirs ) datasets_components = create_train_val_test_datasets ( raw_images , raw_labels ) save_as_csv ( datasets_components [ 0 ], datasets_components [ 1 ], train_dataset_address ) save_as_csv ( datasets_components [ 2 ], datasets_components [ 3 ], val_dataset_address ) save_as_csv ( datasets_components [ 4 ], datasets_components [ 5 ], test_dataset_address ) save_as_csv ( filenames , labels , destination ) Save two lists of observations, labels as a csv files. Parameters: Name Type Description Default filenames List[pathlib.Path] Liste des adresses des images, premi\u00e8re colonne. required labels List[str] Liste des labels correspondants, seconde colonne. required destination Path adresse du dossier o\u00f9 est sauvegard\u00e9 le csv. required Source code in src/make_dataset.py def save_as_csv ( filenames : List [ Path ], labels : List [ str ], destination : Path ) -> None : \"\"\"Save two lists of observations, labels as a csv files. Args: filenames (List[str]): Liste des adresses des images, premi\u00e8re colonne. labels (List[str]): Liste des labels correspondants, seconde colonne. destination (Path): adresse du dossier o\u00f9 est sauvegard\u00e9 le csv. \"\"\" labels_distribution = Counter ( labels ) logger . info ( f \"Saving dataset in { destination } .\" ) logger . info ( f \"Labels distribution { labels_distribution } .\" ) header = [ \"filename\" , \"label\" ] with open ( destination , \"w\" , newline = \"\" ) as saved_csv : writer = csv . writer ( saved_csv , delimiter = \",\" ) writer . writerow ( header ) writer . writerows ( zip ( filenames , labels ))","title":"Initialisation"},{"location":"make_dataset/#initialisation-du-dataset","text":"","title":"Initialisation du dataset"},{"location":"make_dataset/#src.make_dataset","text":"","title":"src.make_dataset"},{"location":"make_dataset/#src.make_dataset.create_train_val_test_datasets","text":"Creation of datasets. Create three image datasets (train, validation, and test) given raw_images and raw_labels . The first step is to gather raw_images and raw_labels in a single dataset entity, then shuffle it, this is to ensure that the dataset is already well shuffled before the before using the scikit_learn module train_test_split (for example dataset could be alphabetically sorted before the shuffling). Then dataset passes into train_test_split to first get the images_train and labels_train and an intermediate images_val and labels_val . The intermediate images_val and labels_val is then again split in half to get the actual images_val , labels_val , images_test , labels_test . Parameters: Name Type Description Default raw_images List[pathlib.Path] Full list of the images used for the three datasets. required raw_labels List[str] Full list of the labels used for the three datasets. required test_size Optional[float] Ratio used in the first use of train_test_split . Defaults to split. 0.25 Returns: Type Description Tuple[List[pathlib.Path], List[str], List[pathlib.Path], List[str], List[pathlib.Path], List[str]] Datasets: The three \"datasets\" returned as lists of images, labels. Note Datasets is the alias for the following type. python Datasets = Tuple[ List[Path], List[str], List[Path], List[str], List[Path], List[str] ] Source code in src/make_dataset.py def create_train_val_test_datasets ( raw_images : List [ Path ], raw_labels : List [ str ], test_size : Optional [ float ] = split , ) -> Datasets : \"\"\"Creation of datasets. Create three image datasets (train, validation, and test) given `raw_images` and `raw_labels`. The first step is to gather `raw_images` and `raw_labels` in a single `dataset` entity, then shuffle it, this is to ensure that the dataset is already well shuffled before the before using the `scikit_learn` module `train_test_split` (for example `dataset` could be alphabetically sorted before the shuffling). Then `dataset` passes into `train_test_split` to first get the `images_train` and `labels_train` and an intermediate `images_val` and `labels_val`. The intermediate `images_val` and `labels_val` is then again split in half to get the actual `images_val`, `labels_val`, `images_test`, `labels_test`. Args: raw_images (List[Path]): Full list of the images used for the three datasets. raw_labels (List[str]): Full list of the labels used for the three datasets. test_size (Optional[float], optional): Ratio used in the first use of `train_test_split`. Defaults to split. Returns: Datasets: The three \"datasets\" returned as lists of images, labels. Note: Datasets is the alias for the following type. ```python Datasets = Tuple[ List[Path], List[str], List[Path], List[str], List[Path], List[str] ]``` \"\"\" set_seed ( random_seed ) dataset = list ( zip ( raw_images , raw_labels )) random . shuffle ( dataset ) shuffled_images , shuffled_labels = zip ( * dataset ) images_train , images_val , labels_train , labels_val = train_test_split ( shuffled_images , shuffled_labels , test_size = test_size , random_state = random_seed , ) images_val , images_test , labels_val , labels_test = train_test_split ( images_val , labels_val , test_size = 0.5 , random_state = random_seed ) return ( images_train , labels_train , images_val , labels_val , images_test , labels_test , )","title":"create_train_val_test_datasets()"},{"location":"make_dataset/#src.make_dataset.get_files_paths","text":"Given an extension, gives a list of files and a list of subdirectories. Starting from root_directory , recursively search all subdirs of root_directory for all files of the given extension . We suppose here that each subdir corresponds to a different class in a classification problem, ie : root_directory | |___ subdir_A (class_A) |___ subdir_B (class_B) |___ ... Parameters: Name Type Description Default root_directory Path Root directory where to start the recursive search. required extension Optional[str] Type of files we want to list during the recursive search. Defaults to \".jpg\". '.jpg' Returns: Type Description Tuple[List[pathlib.Path], List[pathlib.Path]] The list of all files of the given extension, and the list of all the subdirectories. Source code in src/make_dataset.py def get_files_paths ( root_directory : Path , extension : Optional [ str ] = \".jpg\" ) -> Tuple [ List [ Path ], List [ Path ]]: \"\"\"Given an extension, gives a list of files and a list of subdirectories. Starting from `root_directory`, recursively search all subdirs of `root_directory` for all files of the given `extension`. We suppose here that each subdir corresponds to a different class in a classification problem, ie : root_directory | |___ subdir_A (class_A) |___ subdir_B (class_B) |___ ... Args: root_directory (Path): Root directory where to start the recursive search. extension (Optional[str], optional): Type of files we want to list during the recursive search. Defaults to \".jpg\". Returns: The list of all files of the given extension, and the list of all the subdirectories. \"\"\" subdirs = [ subdir for subdir in Path ( root_directory ) . iterdir () if subdir . is_dir ()] logger . info ( f \"Found subfolders : { subdirs } \" ) logger . info ( f \"Searching { extension } files\" ) files_paths = sorted ( image for image in Path ( root_directory ) . glob ( f \"**/* { extension } \" ) if image . is_file () ) num_files = len ( files_paths ) logger . info ( f \"Found { num_files } files\" ) return files_paths , subdirs","title":"get_files_paths()"},{"location":"make_dataset/#src.make_dataset.get_images_paths_and_labels","text":"Creation of a representation of a dataset as lists (image, label). Given a list of images_paths and a list of folders , create two lists in bijection with each other, meaning to each row (an image path) in the first list corresponds a row (a label) in the second list. Also checks if the labels in the two lists correspond. Parameters: Name Type Description Default images_paths List[pathlib.Path] List containing all the images_paths. required folders List[pathlib.Path] List constaining the folders (labels). required Note The paths given here are the absolute ones, not the relative ones. Be sure to have the rights paths when changing from one workspace to another. Exceptions: Type Description ValueError Class deduced from image_path which isn't in 'folders' list. Note image_path.parent has to be in folders . Otherwise that would mean that the first list images_paths contains more classes than the list folders . Raise an error if so. Returns: Type Description Tuple[List[pathlib.Path], List[str]] The two lists being in bijection image <-> label. Source code in src/make_dataset.py def get_images_paths_and_labels ( images_paths : List [ Path ], folders : List [ Path ] ) -> Tuple [ List [ Path ], List [ str ]]: \"\"\"Creation of a representation of a dataset as lists (image, label). Given a list of `images_paths` and a list of `folders`, create two lists in bijection with each other, meaning to each row (an image path) in the first list corresponds a row (a label) in the second list. Also checks if the labels in the two lists correspond. Args: images_paths (List[Path]): List containing all the images_paths. folders (List[Path]): List constaining the folders (labels). Note: The paths given here are the absolute ones, not the relative ones. Be sure to have the rights paths when changing from one workspace to another. Raises: ValueError: Class deduced from image_path which isn't in 'folders' list. Note: `image_path.parent` has to be in `folders`. Otherwise that would mean that the first list `images_paths` contains more classes than the list `folders`. Raise an error if so. Returns: The two lists being in bijection image <-> label. \"\"\" images = [] labels = [] logger . info ( \"Creating images <-> labels representation.\" ) for image_path in images_paths : filename = image_path . absolute () folder = image_path . parent . name if image_path . parent in folders : images . append ( filename ) labels . append ( folder ) else : raise ValueError ( \"Class deduced from image_path which isn't in 'folders' list.\" ) return images , labels","title":"get_images_paths_and_labels()"},{"location":"make_dataset/#src.make_dataset.main","text":"Main function. Source code in src/make_dataset.py @app . command () def main () -> None : \"\"\"Main function.\"\"\" files_paths , subdirs = get_files_paths ( raw_dataset_address ) raw_images , raw_labels = get_images_paths_and_labels ( files_paths , subdirs ) datasets_components = create_train_val_test_datasets ( raw_images , raw_labels ) save_as_csv ( datasets_components [ 0 ], datasets_components [ 1 ], train_dataset_address ) save_as_csv ( datasets_components [ 2 ], datasets_components [ 3 ], val_dataset_address ) save_as_csv ( datasets_components [ 4 ], datasets_components [ 5 ], test_dataset_address )","title":"main()"},{"location":"make_dataset/#src.make_dataset.save_as_csv","text":"Save two lists of observations, labels as a csv files. Parameters: Name Type Description Default filenames List[pathlib.Path] Liste des adresses des images, premi\u00e8re colonne. required labels List[str] Liste des labels correspondants, seconde colonne. required destination Path adresse du dossier o\u00f9 est sauvegard\u00e9 le csv. required Source code in src/make_dataset.py def save_as_csv ( filenames : List [ Path ], labels : List [ str ], destination : Path ) -> None : \"\"\"Save two lists of observations, labels as a csv files. Args: filenames (List[str]): Liste des adresses des images, premi\u00e8re colonne. labels (List[str]): Liste des labels correspondants, seconde colonne. destination (Path): adresse du dossier o\u00f9 est sauvegard\u00e9 le csv. \"\"\" labels_distribution = Counter ( labels ) logger . info ( f \"Saving dataset in { destination } .\" ) logger . info ( f \"Labels distribution { labels_distribution } .\" ) header = [ \"filename\" , \"label\" ] with open ( destination , \"w\" , newline = \"\" ) as saved_csv : writer = csv . writer ( saved_csv , delimiter = \",\" ) writer . writerow ( header ) writer . writerows ( zip ( filenames , labels ))","title":"save_as_csv()"},{"location":"resnet/","text":"Mod\u00e8le ResNet bn_relu_conv ( tensor , filters , kernel_size , strides ) [summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required kernel_size Tuple[int, int] [description] required strides Tuple[int, int] [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def bn_relu_conv ( tensor : tf . Tensor , filters : int , kernel_size : Tuple [ int , int ], strides : Tuple [ int , int ], ) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] kernel_size (List[int]): [description] strides (List[int]): [description] Returns: tf.Tensor: [description] \"\"\" img = BatchNormalization ()( tensor ) img = ReLU ()( img ) return Conv2D ( filters = filters , kernel_size = kernel_size , strides = strides , padding = \"same\" , kernel_initializer = \"he_normal\" , use_bias = False , )( img ) bottleneck_block ( tensor , filters , strides , repets ) [summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required repets int [description] required strides Tuple[int, int] [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def bottleneck_block ( tensor : tf . Tensor , filters : int , strides : Tuple [ int , int ], repets : int , ) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] repets (int): [description] strides (List[int]): [description] Returns: tf.Tensor: [description] \"\"\" img = proj_block ( tensor , filters , strides ) for _ in range ( repets - 1 ): img = resnet_block ( img , filters = filters ) return img get_cnn ( img_shape , n_classes , repets ) [summary]. Parameters: Name Type Description Default img_shape List[int] [description]. Defaults to img_shape. required n_classes Optional[int] [description]. Defaults to n_classes. required repets int [description]. Defaults to repetitions. required Returns: Type Description Model tf.keras.Model: [description] Source code in src/model/resnet.py def get_cnn ( img_shape : List [ int ], n_classes : Optional [ int ], repets : int , ) -> tf . keras . Model : \"\"\"[summary]. Args: img_shape (List[int], optional): [description]. Defaults to img_shape. n_classes (int, optional): [description]. Defaults to n_classes. repets (int): [description]. Defaults to repetitions. Returns: tf.keras.Model: [description] \"\"\" img_input = Input ( img_shape ) img = Conv2D ( filters = 16 , kernel_size = ( 3 , 3 ), padding = \"same\" , kernel_initializer = \"he_normal\" , use_bias = False , )( img_input ) img = bottleneck_block ( img , filters = 64 , repets = repets , strides = size_one ) img = bottleneck_block ( img , filters = 128 , repets = repets , strides = ( 2 , 2 )) img = bottleneck_block ( img , filters = 256 , repets = repets , strides = ( 2 , 2 )) img = BatchNormalization ()( img ) img = ReLU ()( img ) img = GlobalAvgPool2D ()( img ) img = Dense ( n_classes )( img ) output = Activation ( \"softmax\" )( img ) return Model ( img_input , output ) proj_block ( tensor , filters , strides ) [summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required strides Tuple[int, int] [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def proj_block ( tensor : tf . Tensor , filters : int , strides : Tuple [ int , int ]) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] strides (List[int]): [description] Returns: tf.Tensor: [description] \"\"\" inner_filters = filters // 4 img = BatchNormalization ()( tensor ) out1 = ReLU ()( img ) # shortcut out2 = Conv2D ( filters = filters , kernel_size = size_one , padding = \"same\" , strides = strides , kernel_initializer = \"he_normal\" , use_bias = False , )( out1 ) # main stream out3 = bn_relu_conv ( out1 , inner_filters , kernel_size = size_one , strides = strides ) out3 = bn_relu_conv ( out3 , inner_filters , kernel_size = ( 3 , 3 ), strides = size_one ) out3 = bn_relu_conv ( out3 , filters , kernel_size = size_one , strides = size_one ) return Add ()([ out2 , out3 ]) resnet_block ( tensor , filters ) [summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def resnet_block ( tensor : tf . Tensor , filters : int ) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] Returns: tf.Tensor: [description] \"\"\" inner_filters = filters // 4 img = bn_relu_conv ( tensor , inner_filters , kernel_size = size_one , strides = size_one ) img = bn_relu_conv ( img , inner_filters , kernel_size = ( 3 , 3 ), strides = size_one ) img = bn_relu_conv ( img , filters , kernel_size = size_one , strides = size_one ) return Add ()([ img , tensor ])","title":"Architecture ResNet"},{"location":"resnet/#modele-resnet","text":"","title":"Mod\u00e8le ResNet"},{"location":"resnet/#src.model.resnet","text":"","title":"src.model.resnet"},{"location":"resnet/#src.model.resnet.bn_relu_conv","text":"[summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required kernel_size Tuple[int, int] [description] required strides Tuple[int, int] [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def bn_relu_conv ( tensor : tf . Tensor , filters : int , kernel_size : Tuple [ int , int ], strides : Tuple [ int , int ], ) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] kernel_size (List[int]): [description] strides (List[int]): [description] Returns: tf.Tensor: [description] \"\"\" img = BatchNormalization ()( tensor ) img = ReLU ()( img ) return Conv2D ( filters = filters , kernel_size = kernel_size , strides = strides , padding = \"same\" , kernel_initializer = \"he_normal\" , use_bias = False , )( img )","title":"bn_relu_conv()"},{"location":"resnet/#src.model.resnet.bottleneck_block","text":"[summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required repets int [description] required strides Tuple[int, int] [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def bottleneck_block ( tensor : tf . Tensor , filters : int , strides : Tuple [ int , int ], repets : int , ) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] repets (int): [description] strides (List[int]): [description] Returns: tf.Tensor: [description] \"\"\" img = proj_block ( tensor , filters , strides ) for _ in range ( repets - 1 ): img = resnet_block ( img , filters = filters ) return img","title":"bottleneck_block()"},{"location":"resnet/#src.model.resnet.get_cnn","text":"[summary]. Parameters: Name Type Description Default img_shape List[int] [description]. Defaults to img_shape. required n_classes Optional[int] [description]. Defaults to n_classes. required repets int [description]. Defaults to repetitions. required Returns: Type Description Model tf.keras.Model: [description] Source code in src/model/resnet.py def get_cnn ( img_shape : List [ int ], n_classes : Optional [ int ], repets : int , ) -> tf . keras . Model : \"\"\"[summary]. Args: img_shape (List[int], optional): [description]. Defaults to img_shape. n_classes (int, optional): [description]. Defaults to n_classes. repets (int): [description]. Defaults to repetitions. Returns: tf.keras.Model: [description] \"\"\" img_input = Input ( img_shape ) img = Conv2D ( filters = 16 , kernel_size = ( 3 , 3 ), padding = \"same\" , kernel_initializer = \"he_normal\" , use_bias = False , )( img_input ) img = bottleneck_block ( img , filters = 64 , repets = repets , strides = size_one ) img = bottleneck_block ( img , filters = 128 , repets = repets , strides = ( 2 , 2 )) img = bottleneck_block ( img , filters = 256 , repets = repets , strides = ( 2 , 2 )) img = BatchNormalization ()( img ) img = ReLU ()( img ) img = GlobalAvgPool2D ()( img ) img = Dense ( n_classes )( img ) output = Activation ( \"softmax\" )( img ) return Model ( img_input , output )","title":"get_cnn()"},{"location":"resnet/#src.model.resnet.proj_block","text":"[summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required strides Tuple[int, int] [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def proj_block ( tensor : tf . Tensor , filters : int , strides : Tuple [ int , int ]) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] strides (List[int]): [description] Returns: tf.Tensor: [description] \"\"\" inner_filters = filters // 4 img = BatchNormalization ()( tensor ) out1 = ReLU ()( img ) # shortcut out2 = Conv2D ( filters = filters , kernel_size = size_one , padding = \"same\" , strides = strides , kernel_initializer = \"he_normal\" , use_bias = False , )( out1 ) # main stream out3 = bn_relu_conv ( out1 , inner_filters , kernel_size = size_one , strides = strides ) out3 = bn_relu_conv ( out3 , inner_filters , kernel_size = ( 3 , 3 ), strides = size_one ) out3 = bn_relu_conv ( out3 , filters , kernel_size = size_one , strides = size_one ) return Add ()([ out2 , out3 ])","title":"proj_block()"},{"location":"resnet/#src.model.resnet.resnet_block","text":"[summary]. Parameters: Name Type Description Default tensor Tensor [description] required filters int [description] required Returns: Type Description Tensor tf.Tensor: [description] Source code in src/model/resnet.py def resnet_block ( tensor : tf . Tensor , filters : int ) -> tf . Tensor : \"\"\"[summary]. Args: tensor (tf.Tensor): [description] filters (int): [description] Returns: tf.Tensor: [description] \"\"\" inner_filters = filters // 4 img = bn_relu_conv ( tensor , inner_filters , kernel_size = size_one , strides = size_one ) img = bn_relu_conv ( img , inner_filters , kernel_size = ( 3 , 3 ), strides = size_one ) img = bn_relu_conv ( img , filters , kernel_size = size_one , strides = size_one ) return Add ()([ img , tensor ])","title":"resnet_block()"},{"location":"tensorize/","text":"Pipeline pour la transformation des donn\u00e9es Tensorize Class used to create tensor datasets for TensorFlow. Parameters: Name Type Description Default object object The base class of the class hierarchy, used only to enforce WPS306. See https://wemake-python-stylegui.de/en/latest/pages/usage/ violations/consistency.html#consistency. required __init__ ( self , n_classes , img_shape , random_seed ) special Initialization of the class Featurize. Initialize the class the number of classes in the datasets, the shape of the images and the random seed. Parameters: Name Type Description Default n_classes int Number of classes in the dataset. required img_shape Tuple[int, int, int] Dimension of the image, format is (H,W,C). required random_seed int Fixed random seed for reproducibility. required Source code in src/tensorize.py def __init__ ( self , n_classes : int , img_shape : Tuple [ int , int , int ], random_seed : int ) -> None : \"\"\"Initialization of the class Featurize. Initialize the class the number of classes in the datasets, the shape of the images and the random seed. Args: n_classes (int): Number of classes in the dataset. img_shape (Tuple[int, int, int]): Dimension of the image, format is (H,W,C). random_seed (int): Fixed random seed for reproducibility. \"\"\" self . n_classes = n_classes self . img_shape = img_shape self . random_seed = random_seed self . AUTOTUNE = tf . data . experimental . AUTOTUNE create_dataset ( self , data_path , batch , repet , prefetch , augment ) Creation of a tensor dataset for TensorFlow. Parameters: Name Type Description Default data_path str Path where the csv file containing the dataframe is located. required batch int Batch size, usually 32. required repet int How many times the dataset has to be repeated. required prefetch int How many batch the CPU has to prepare in advance for the GPU. required augment bool Does the dataset has to be augmented or no. required Returns: Type Description DatasetV2 A batch of observations and labels. Source code in src/tensorize.py def create_dataset ( self , data_path : str , batch : int , repet : int , prefetch : int , augment : bool , ) -> tf . data . Dataset : \"\"\"Creation of a tensor dataset for TensorFlow. Args: data_path (str): Path where the csv file containing the dataframe is located. batch (int): Batch size, usually 32. repet (int): How many times the dataset has to be repeated. prefetch (int): How many batch the CPU has to prepare in advance for the GPU. augment (bool): Does the dataset has to be augmented or no. Returns: A batch of observations and labels. \"\"\" df = pd . read_csv ( data_path ) features = self . load_images ( data_frame = df , column_name = \"filename\" ) labels = self . load_labels ( data_frame = df , column_name = \"label\" ) dataset = tf . data . Dataset . from_tensor_slices (( features , labels )) dataset = dataset . shuffle ( len ( features ), seed = self . random_seed ) dataset = dataset . repeat ( repet ) dataset = dataset . map ( self . parse_image_and_label , num_parallel_calls = self . AUTOTUNE ) if augment : dataset = dataset . map ( self . train_preprocess , num_parallel_calls = self . AUTOTUNE ) dataset = dataset . batch ( batch ) dataset = dataset . cache () return dataset . prefetch ( prefetch ) load_images ( self , data_frame , column_name ) Load the images as a list. Take the dataframe containing the observations and the labels and the return the column containing the observations as a list. Parameters: Name Type Description Default data_frame DataFrame Dataframe containing the dataset. required column_name str The name of the column containing the observations. required Returns: Type Description List[str] The list of observations deduced from the dataframe. Source code in src/tensorize.py def load_images ( self , data_frame : pd . DataFrame , column_name : str ) -> List [ str ]: \"\"\"Load the images as a list. Take the dataframe containing the observations and the labels and the return the column containing the observations as a list. Args: data_frame (pd.DataFrame): Dataframe containing the dataset. column_name (str): The name of the column containing the observations. Returns: The list of observations deduced from the dataframe. \"\"\" return data_frame [ column_name ] . tolist () load_labels ( self , data_frame , column_name ) Load the labels as a list and encode them. Take the dataframe containing the observations and the labels and the return the column containing the labels as an encoded list. The encoding is done by taking the set of labels, alphabetically sorted, and then transforming them as integers starting from 0. from sklearn.preprocessing import LabelEncoder works well to encode labels, but if the dataset is huge, the time it takes to encode all the labels is growing fast. We use anumpy and vectorization to speed up the time. See the StackOverflow question : Question Parameters: Name Type Description Default data_frame DataFrame Dataframe containing the dataset. required column_name str The name of the column containing the labels. required Returns: Type Description List[int] The list of encoded labels deduced from the dataframe. Source code in src/tensorize.py def load_labels ( self , data_frame : pd . DataFrame , column_name : str ) -> List [ int ]: \"\"\"Load the labels as a list and encode them. Take the dataframe containing the observations and the labels and the return the column containing the labels as an encoded list. The encoding is done by taking the set of labels, alphabetically sorted, and then transforming them as integers starting from 0. `from sklearn.preprocessing import LabelEncoder` works well to encode labels, but if the dataset is huge, the time it takes to encode all the labels is growing fast. We use anumpy and vectorization to speed up the time. See the StackOverflow question : [Question](https://stackoverflow.com/questions/45321999/ how-can-i-optimize-label-encoding-for-large-data-sets-sci-kit-learn) Args: data_frame (pd.DataFrame): Dataframe containing the dataset. column_name (str): The name of the column containing the labels. Returns: The list of encoded labels deduced from the dataframe. \"\"\" label_list = data_frame [ column_name ] . tolist () classes = sorted ( set ( label_list )) logger . info ( f \"Found following labels { classes } \" ) labels = np . unique ( label_list , return_inverse = True )[ 1 ] # type: ignore dic = dict ( zip ( label_list , labels )) # type: Dict[str, int] logger . info ( f \"Dictionnary creation { dic } \" ) vectorized_get = np . vectorize ( dic . get ) # type: ignore return vectorized_get ( label_list ) parse_image_and_label ( self , filename , label ) Transform image and label. Parse image to go from path to a resized np.ndarray, and parse the labels to one-hot encode them. Parameters: Name Type Description Default filename str The path of the image to parse. required label int The label of the image, as an int, to one-hot encode. required Returns: Type Description Tuple[numpy.ndarray, int] A np.ndarray corresponding to the image and the corresponding one-hot label. Source code in src/tensorize.py def parse_image_and_label ( self , filename : str , label : int ) -> Tuple [ np . ndarray , int ]: # type: ignore \"\"\"Transform image and label. Parse image to go from path to a resized np.ndarray, and parse the labels to one-hot encode them. Args: filename (str): The path of the image to parse. label (int): The label of the image, as an int, to one-hot encode. Returns: A np.ndarray corresponding to the image and the corresponding one-hot label. \"\"\" resized_dims = [ self . img_shape [ 0 ], self . img_shape [ 1 ]] # convert the label to one-hot encoding label = tf . one_hot ( label , self . n_classes ) # decode image image = tf . io . read_file ( filename ) # Don't use tf.image.decode_image, # or the output shape will be undefined image = tf . image . decode_jpeg ( image ) # This will convert to float values in [0, 1] image = tf . image . convert_image_dtype ( image , tf . float32 ) image = tf . image . resize ( image , resized_dims ) return image , label train_preprocess ( self , image , label ) Augmentation preprocess, if needed. Parameters: Name Type Description Default image ndarray The image to augment. required label List[int] The corresponding label. required Returns: Type Description Tuple[numpy.ndarray, List[int]] The augmented pair. Source code in src/tensorize.py def train_preprocess ( self , image : np . ndarray , label : List [ int ] # type: ignore ) -> Tuple [ np . ndarray , List [ int ]]: # type: ignore \"\"\"Augmentation preprocess, if needed. Args: image (np.ndarray): The image to augment. label (List[int]): The corresponding label. Returns: The augmented pair. \"\"\" image = tf . image . random_flip_left_right ( image ) image = tf . image . random_flip_up_down ( image ) return image , label","title":"Transformation des donn\u00e9es"},{"location":"tensorize/#pipeline-pour-la-transformation-des-donnees","text":"","title":"Pipeline pour la transformation des donn\u00e9es"},{"location":"tensorize/#src.tensorize","text":"","title":"src.tensorize"},{"location":"tensorize/#src.tensorize.Tensorize","text":"Class used to create tensor datasets for TensorFlow. Parameters: Name Type Description Default object object The base class of the class hierarchy, used only to enforce WPS306. See https://wemake-python-stylegui.de/en/latest/pages/usage/ violations/consistency.html#consistency. required","title":"Tensorize"},{"location":"tensorize/#src.tensorize.Tensorize.__init__","text":"Initialization of the class Featurize. Initialize the class the number of classes in the datasets, the shape of the images and the random seed. Parameters: Name Type Description Default n_classes int Number of classes in the dataset. required img_shape Tuple[int, int, int] Dimension of the image, format is (H,W,C). required random_seed int Fixed random seed for reproducibility. required Source code in src/tensorize.py def __init__ ( self , n_classes : int , img_shape : Tuple [ int , int , int ], random_seed : int ) -> None : \"\"\"Initialization of the class Featurize. Initialize the class the number of classes in the datasets, the shape of the images and the random seed. Args: n_classes (int): Number of classes in the dataset. img_shape (Tuple[int, int, int]): Dimension of the image, format is (H,W,C). random_seed (int): Fixed random seed for reproducibility. \"\"\" self . n_classes = n_classes self . img_shape = img_shape self . random_seed = random_seed self . AUTOTUNE = tf . data . experimental . AUTOTUNE","title":"__init__()"},{"location":"tensorize/#src.tensorize.Tensorize.create_dataset","text":"Creation of a tensor dataset for TensorFlow. Parameters: Name Type Description Default data_path str Path where the csv file containing the dataframe is located. required batch int Batch size, usually 32. required repet int How many times the dataset has to be repeated. required prefetch int How many batch the CPU has to prepare in advance for the GPU. required augment bool Does the dataset has to be augmented or no. required Returns: Type Description DatasetV2 A batch of observations and labels. Source code in src/tensorize.py def create_dataset ( self , data_path : str , batch : int , repet : int , prefetch : int , augment : bool , ) -> tf . data . Dataset : \"\"\"Creation of a tensor dataset for TensorFlow. Args: data_path (str): Path where the csv file containing the dataframe is located. batch (int): Batch size, usually 32. repet (int): How many times the dataset has to be repeated. prefetch (int): How many batch the CPU has to prepare in advance for the GPU. augment (bool): Does the dataset has to be augmented or no. Returns: A batch of observations and labels. \"\"\" df = pd . read_csv ( data_path ) features = self . load_images ( data_frame = df , column_name = \"filename\" ) labels = self . load_labels ( data_frame = df , column_name = \"label\" ) dataset = tf . data . Dataset . from_tensor_slices (( features , labels )) dataset = dataset . shuffle ( len ( features ), seed = self . random_seed ) dataset = dataset . repeat ( repet ) dataset = dataset . map ( self . parse_image_and_label , num_parallel_calls = self . AUTOTUNE ) if augment : dataset = dataset . map ( self . train_preprocess , num_parallel_calls = self . AUTOTUNE ) dataset = dataset . batch ( batch ) dataset = dataset . cache () return dataset . prefetch ( prefetch )","title":"create_dataset()"},{"location":"tensorize/#src.tensorize.Tensorize.load_images","text":"Load the images as a list. Take the dataframe containing the observations and the labels and the return the column containing the observations as a list. Parameters: Name Type Description Default data_frame DataFrame Dataframe containing the dataset. required column_name str The name of the column containing the observations. required Returns: Type Description List[str] The list of observations deduced from the dataframe. Source code in src/tensorize.py def load_images ( self , data_frame : pd . DataFrame , column_name : str ) -> List [ str ]: \"\"\"Load the images as a list. Take the dataframe containing the observations and the labels and the return the column containing the observations as a list. Args: data_frame (pd.DataFrame): Dataframe containing the dataset. column_name (str): The name of the column containing the observations. Returns: The list of observations deduced from the dataframe. \"\"\" return data_frame [ column_name ] . tolist ()","title":"load_images()"},{"location":"tensorize/#src.tensorize.Tensorize.load_labels","text":"Load the labels as a list and encode them. Take the dataframe containing the observations and the labels and the return the column containing the labels as an encoded list. The encoding is done by taking the set of labels, alphabetically sorted, and then transforming them as integers starting from 0. from sklearn.preprocessing import LabelEncoder works well to encode labels, but if the dataset is huge, the time it takes to encode all the labels is growing fast. We use anumpy and vectorization to speed up the time. See the StackOverflow question : Question Parameters: Name Type Description Default data_frame DataFrame Dataframe containing the dataset. required column_name str The name of the column containing the labels. required Returns: Type Description List[int] The list of encoded labels deduced from the dataframe. Source code in src/tensorize.py def load_labels ( self , data_frame : pd . DataFrame , column_name : str ) -> List [ int ]: \"\"\"Load the labels as a list and encode them. Take the dataframe containing the observations and the labels and the return the column containing the labels as an encoded list. The encoding is done by taking the set of labels, alphabetically sorted, and then transforming them as integers starting from 0. `from sklearn.preprocessing import LabelEncoder` works well to encode labels, but if the dataset is huge, the time it takes to encode all the labels is growing fast. We use anumpy and vectorization to speed up the time. See the StackOverflow question : [Question](https://stackoverflow.com/questions/45321999/ how-can-i-optimize-label-encoding-for-large-data-sets-sci-kit-learn) Args: data_frame (pd.DataFrame): Dataframe containing the dataset. column_name (str): The name of the column containing the labels. Returns: The list of encoded labels deduced from the dataframe. \"\"\" label_list = data_frame [ column_name ] . tolist () classes = sorted ( set ( label_list )) logger . info ( f \"Found following labels { classes } \" ) labels = np . unique ( label_list , return_inverse = True )[ 1 ] # type: ignore dic = dict ( zip ( label_list , labels )) # type: Dict[str, int] logger . info ( f \"Dictionnary creation { dic } \" ) vectorized_get = np . vectorize ( dic . get ) # type: ignore return vectorized_get ( label_list )","title":"load_labels()"},{"location":"tensorize/#src.tensorize.Tensorize.parse_image_and_label","text":"Transform image and label. Parse image to go from path to a resized np.ndarray, and parse the labels to one-hot encode them. Parameters: Name Type Description Default filename str The path of the image to parse. required label int The label of the image, as an int, to one-hot encode. required Returns: Type Description Tuple[numpy.ndarray, int] A np.ndarray corresponding to the image and the corresponding one-hot label. Source code in src/tensorize.py def parse_image_and_label ( self , filename : str , label : int ) -> Tuple [ np . ndarray , int ]: # type: ignore \"\"\"Transform image and label. Parse image to go from path to a resized np.ndarray, and parse the labels to one-hot encode them. Args: filename (str): The path of the image to parse. label (int): The label of the image, as an int, to one-hot encode. Returns: A np.ndarray corresponding to the image and the corresponding one-hot label. \"\"\" resized_dims = [ self . img_shape [ 0 ], self . img_shape [ 1 ]] # convert the label to one-hot encoding label = tf . one_hot ( label , self . n_classes ) # decode image image = tf . io . read_file ( filename ) # Don't use tf.image.decode_image, # or the output shape will be undefined image = tf . image . decode_jpeg ( image ) # This will convert to float values in [0, 1] image = tf . image . convert_image_dtype ( image , tf . float32 ) image = tf . image . resize ( image , resized_dims ) return image , label","title":"parse_image_and_label()"},{"location":"tensorize/#src.tensorize.Tensorize.train_preprocess","text":"Augmentation preprocess, if needed. Parameters: Name Type Description Default image ndarray The image to augment. required label List[int] The corresponding label. required Returns: Type Description Tuple[numpy.ndarray, List[int]] The augmented pair. Source code in src/tensorize.py def train_preprocess ( self , image : np . ndarray , label : List [ int ] # type: ignore ) -> Tuple [ np . ndarray , List [ int ]]: # type: ignore \"\"\"Augmentation preprocess, if needed. Args: image (np.ndarray): The image to augment. label (List[int]): The corresponding label. Returns: The augmented pair. \"\"\" image = tf . image . random_flip_left_right ( image ) image = tf . image . random_flip_up_down ( image ) return image , label","title":"train_preprocess()"},{"location":"test_make_dataset/","text":"Tests unitaires pour le script prepare_dataset df () Returns a test dataframe. Returns: Type Description DataFrame pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. Source code in tests/test_make_dataset.py @pytest . fixture def df () -> pd . DataFrame : \"\"\"Returns a test dataframe. Returns: pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. \"\"\" return pd . read_csv ( \"tests/test_datas/test_datas.csv\" ) root_directory () [summary]. Returns: Type Description [type] [description] Source code in tests/test_make_dataset.py @pytest . fixture def root_directory (): \"\"\"[summary]. Returns: [type]: [description] \"\"\" return Path ( \"tests/test_datas\" ) test_create_train_val_test_datasets ( df ) [summary]. Parameters: Name Type Description Default df [type] [description] required Source code in tests/test_make_dataset.py def test_create_train_val_test_datasets ( df ) -> None : \"\"\"[summary]. Args: df ([type]): [description] \"\"\" raw_images = df [ \"filename\" ] raw_labels = df [ \"label\" ] datasets_components = create_train_val_test_datasets ( raw_images , raw_labels ) assert len ( datasets_components [ 0 ]) == len ( datasets_components [ 1 ]) == 15 assert 2 <= len ( datasets_components [ 2 ]) <= 3 assert 2 <= len ( datasets_components [ 3 ]) <= 3 assert 2 <= len ( datasets_components [ 4 ]) <= 3 assert 2 <= len ( datasets_components [ 5 ]) <= 3 test_get_files_paths ( root_directory ) [summary]. Parameters: Name Type Description Default root_directory [type] [description] required Source code in tests/test_make_dataset.py def test_get_files_paths ( root_directory ) -> None : \"\"\"[summary]. Args: root_directory ([type]): [description] \"\"\" files_paths , subdirs = get_files_paths ( root_directory ) for idx in range ( 20 ): assert isinstance ( files_paths [ idx ], Path ) image_path = Path ( files_paths [ idx ]) assert image_path . is_file () assert isinstance ( subdirs , list ) assert len ( subdirs ) == 2 test_get_images_paths_and_labels ( root_directory ) [summary]. Parameters: Name Type Description Default root_directory [type] [description] required Source code in tests/test_make_dataset.py def test_get_images_paths_and_labels ( root_directory ) -> None : \"\"\"[summary]. Args: root_directory ([type]): [description] \"\"\" files_paths , subdirs = get_files_paths ( root_directory ) images , labels = get_images_paths_and_labels ( files_paths , subdirs ) assert len ( images ) == 20 assert len ( labels ) == 20 for idx in range ( 10 ): assert images [ idx ] . parent . name == \"Negative\" assert images [ 10 + idx ] . parent . name == \"Positive\"","title":"prepare_dataset"},{"location":"test_make_dataset/#tests-unitaires-pour-le-script-prepare_dataset","text":"","title":"Tests unitaires pour le script prepare_dataset"},{"location":"test_make_dataset/#tests.test_make_dataset","text":"","title":"tests.test_make_dataset"},{"location":"test_make_dataset/#tests.test_make_dataset.df","text":"Returns a test dataframe. Returns: Type Description DataFrame pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. Source code in tests/test_make_dataset.py @pytest . fixture def df () -> pd . DataFrame : \"\"\"Returns a test dataframe. Returns: pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. \"\"\" return pd . read_csv ( \"tests/test_datas/test_datas.csv\" )","title":"df()"},{"location":"test_make_dataset/#tests.test_make_dataset.root_directory","text":"[summary]. Returns: Type Description [type] [description] Source code in tests/test_make_dataset.py @pytest . fixture def root_directory (): \"\"\"[summary]. Returns: [type]: [description] \"\"\" return Path ( \"tests/test_datas\" )","title":"root_directory()"},{"location":"test_make_dataset/#tests.test_make_dataset.test_create_train_val_test_datasets","text":"[summary]. Parameters: Name Type Description Default df [type] [description] required Source code in tests/test_make_dataset.py def test_create_train_val_test_datasets ( df ) -> None : \"\"\"[summary]. Args: df ([type]): [description] \"\"\" raw_images = df [ \"filename\" ] raw_labels = df [ \"label\" ] datasets_components = create_train_val_test_datasets ( raw_images , raw_labels ) assert len ( datasets_components [ 0 ]) == len ( datasets_components [ 1 ]) == 15 assert 2 <= len ( datasets_components [ 2 ]) <= 3 assert 2 <= len ( datasets_components [ 3 ]) <= 3 assert 2 <= len ( datasets_components [ 4 ]) <= 3 assert 2 <= len ( datasets_components [ 5 ]) <= 3","title":"test_create_train_val_test_datasets()"},{"location":"test_make_dataset/#tests.test_make_dataset.test_get_files_paths","text":"[summary]. Parameters: Name Type Description Default root_directory [type] [description] required Source code in tests/test_make_dataset.py def test_get_files_paths ( root_directory ) -> None : \"\"\"[summary]. Args: root_directory ([type]): [description] \"\"\" files_paths , subdirs = get_files_paths ( root_directory ) for idx in range ( 20 ): assert isinstance ( files_paths [ idx ], Path ) image_path = Path ( files_paths [ idx ]) assert image_path . is_file () assert isinstance ( subdirs , list ) assert len ( subdirs ) == 2","title":"test_get_files_paths()"},{"location":"test_make_dataset/#tests.test_make_dataset.test_get_images_paths_and_labels","text":"[summary]. Parameters: Name Type Description Default root_directory [type] [description] required Source code in tests/test_make_dataset.py def test_get_images_paths_and_labels ( root_directory ) -> None : \"\"\"[summary]. Args: root_directory ([type]): [description] \"\"\" files_paths , subdirs = get_files_paths ( root_directory ) images , labels = get_images_paths_and_labels ( files_paths , subdirs ) assert len ( images ) == 20 assert len ( labels ) == 20 for idx in range ( 10 ): assert images [ idx ] . parent . name == \"Negative\" assert images [ 10 + idx ] . parent . name == \"Positive\"","title":"test_get_images_paths_and_labels()"},{"location":"test_tensorize/","text":"Tests unitaires pour la classe Featurize df () Returns a test dataframe. Returns: Type Description DataFrame pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. Source code in tests/test_tensorize.py @pytest . fixture def df () -> pd . DataFrame : \"\"\"Returns a test dataframe. Returns: pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. \"\"\" return pd . read_csv ( \"tests/test_datas/test_datas.csv\" ) tensor () Returns a test class. Returns: Type Description Tensorize Tensorize: The class we test here. Defined in src.tensorize.py Source code in tests/test_tensorize.py @pytest . fixture def tensor () -> Tensorize : \"\"\"Returns a test class. Returns: Tensorize: The class we test here. Defined in `src.tensorize.py` \"\"\" return Tensorize ( n_classes = 2 , img_shape = ( 224 , 224 , 3 ), random_seed = 42 ) test_constructor () Test that the constructor is weel defined. You should only need the three following parameters to initiate this class : The number of classes in the dataset. The dimensions of the images. The random seed for reproducibility. Source code in tests/test_tensorize.py def test_constructor () -> None : \"\"\"Test that the constructor is weel defined. You should only need the three following parameters to initiate this class : 1. The number of classes in the dataset. 2. The dimensions of the images. 3. The random seed for reproducibility. \"\"\" ts = Tensorize ( n_classes = 2 , img_shape = ( 224 , 224 , 3 ), random_seed = 42 ) assert isinstance ( ts , Tensorize ) test_create_dataset_with_augment ( tensor ) [summary]. Parameters: Name Type Description Default tensor [type] [description] required df [type] [description] required Source code in tests/test_tensorize.py def test_create_dataset_with_augment ( tensor ): \"\"\"[summary]. Args: tensor ([type]): [description] df ([type]): [description] \"\"\" ds = tensor . create_dataset ( \"tests/test_datas/test_datas.csv\" , batch = 5 , repet = 1 , prefetch = 1 , augment = True ) for imgs , _ in ds . take ( 1 ): assert imgs . numpy () . shape == ( 5 , 224 , 224 , 3 ) test_create_dataset_without_augment ( tensor ) [summary]. Parameters: Name Type Description Default tensor [type] [description] required df [type] [description] required Source code in tests/test_tensorize.py def test_create_dataset_without_augment ( tensor ): \"\"\"[summary]. Args: tensor ([type]): [description] df ([type]): [description] \"\"\" ds = tensor . create_dataset ( \"tests/test_datas/test_datas.csv\" , batch = 5 , repet = 1 , prefetch = 1 , augment = False ) for imgs , _ in ds . take ( 1 ): assert imgs . numpy () . shape == ( 5 , 224 , 224 , 3 ) test_load_images ( tensor , df ) Test of the function load_images . The function should take the column 'filename' of the dataframe en return it as a list. Also checks that we have the right number of elements in the list. Parameters: Name Type Description Default tensor Tensorize [description] required df DataFrame [description] required Source code in tests/test_tensorize.py def test_load_images ( tensor : Tensorize , df : pd . DataFrame ) -> None : \"\"\"Test of the function `load_images`. The function should take the column 'filename' of the dataframe en return it as a list. Also checks that we have the right number of elements in the list. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" filenames = tensor . load_images ( data_frame = df , column_name = \"filename\" ) assert isinstance ( filenames , list ) assert len ( filenames ) == 20 for idx in range ( 20 ): assert isinstance ( filenames [ idx ], str ) image_path = Path ( filenames [ idx ]) assert image_path . is_file () test_load_labels ( tensor , df ) Test load_labels function. Parameters: Name Type Description Default tensor Tensorize [description] required df DataFrame [description] required Source code in tests/test_tensorize.py def test_load_labels ( tensor : Tensorize , df : pd . DataFrame ) -> None : \"\"\"Test load_labels function. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" zeros = [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] ones = [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ] labels_test = zeros + ones labels_list = tensor . load_labels ( data_frame = df , column_name = \"label\" ) assert len ( labels_list ) == 20 for idx in range ( 20 ): assert labels_list [ idx ] == labels_test [ idx ] test_parse_image_and_label ( tensor , df ) [summary]. Parameters: Name Type Description Default tensor Tensorize [description] required df DataFrame [description] required Source code in tests/test_tensorize.py def test_parse_image_and_label ( tensor : Tensorize , df : pd . DataFrame ) -> None : \"\"\"[summary]. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" label1 = 0 label2 = 1 img1 , oh_label1 = tensor . parse_image_and_label ( df [ \"filename\" ][ 0 ], label1 ) _ , oh_label2 = tensor . parse_image_and_label ( df [ \"filename\" ][ 10 ], label2 ) assert isinstance ( img1 , tf . Tensor ) assert isinstance ( oh_label1 , tf . Tensor ) assert img1 . numpy () . shape == ( 224 , 224 , 3 ) oh_label10 = oh_label1 . numpy ()[ 0 ] oh_label11 = oh_label1 . numpy ()[ 1 ] oh_label20 = oh_label2 . numpy ()[ 0 ] oh_label21 = oh_label2 . numpy ()[ 1 ] assert ( oh_label10 , oh_label11 ) == ( 1 , 0 ) assert ( oh_label20 , oh_label21 ) == ( 0 , 1 ) test_train_prepocess ( tensor ) [summary]. Parameters: Name Type Description Default tensor Tensorize [description] required df pd.DataFrame [description] required Source code in tests/test_tensorize.py def test_train_prepocess ( tensor : Tensorize ) -> None : \"\"\"[summary]. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" oh_label = [ 0 , 1 ] img_rdn = np . random . rand ( 224 , 224 , 3 ) img , _ = tensor . train_preprocess ( img_rdn , oh_label ) assert img . numpy () . shape == ( 224 , 224 , 3 )","title":"tensorize"},{"location":"test_tensorize/#tests-unitaires-pour-la-classe-featurize","text":"","title":"Tests unitaires pour la classe Featurize"},{"location":"test_tensorize/#tests.test_tensorize","text":"","title":"tests.test_tensorize"},{"location":"test_tensorize/#tests.test_tensorize.df","text":"Returns a test dataframe. Returns: Type Description DataFrame pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. Source code in tests/test_tensorize.py @pytest . fixture def df () -> pd . DataFrame : \"\"\"Returns a test dataframe. Returns: pd.DataFrame: Test dataframe with manually crafted rows to check behavior during testing. Has 20 rows : 10 with 'Negative' elements followed by 10 with 'Positive' elements. \"\"\" return pd . read_csv ( \"tests/test_datas/test_datas.csv\" )","title":"df()"},{"location":"test_tensorize/#tests.test_tensorize.tensor","text":"Returns a test class. Returns: Type Description Tensorize Tensorize: The class we test here. Defined in src.tensorize.py Source code in tests/test_tensorize.py @pytest . fixture def tensor () -> Tensorize : \"\"\"Returns a test class. Returns: Tensorize: The class we test here. Defined in `src.tensorize.py` \"\"\" return Tensorize ( n_classes = 2 , img_shape = ( 224 , 224 , 3 ), random_seed = 42 )","title":"tensor()"},{"location":"test_tensorize/#tests.test_tensorize.test_constructor","text":"Test that the constructor is weel defined. You should only need the three following parameters to initiate this class : The number of classes in the dataset. The dimensions of the images. The random seed for reproducibility. Source code in tests/test_tensorize.py def test_constructor () -> None : \"\"\"Test that the constructor is weel defined. You should only need the three following parameters to initiate this class : 1. The number of classes in the dataset. 2. The dimensions of the images. 3. The random seed for reproducibility. \"\"\" ts = Tensorize ( n_classes = 2 , img_shape = ( 224 , 224 , 3 ), random_seed = 42 ) assert isinstance ( ts , Tensorize )","title":"test_constructor()"},{"location":"test_tensorize/#tests.test_tensorize.test_create_dataset_with_augment","text":"[summary]. Parameters: Name Type Description Default tensor [type] [description] required df [type] [description] required Source code in tests/test_tensorize.py def test_create_dataset_with_augment ( tensor ): \"\"\"[summary]. Args: tensor ([type]): [description] df ([type]): [description] \"\"\" ds = tensor . create_dataset ( \"tests/test_datas/test_datas.csv\" , batch = 5 , repet = 1 , prefetch = 1 , augment = True ) for imgs , _ in ds . take ( 1 ): assert imgs . numpy () . shape == ( 5 , 224 , 224 , 3 )","title":"test_create_dataset_with_augment()"},{"location":"test_tensorize/#tests.test_tensorize.test_create_dataset_without_augment","text":"[summary]. Parameters: Name Type Description Default tensor [type] [description] required df [type] [description] required Source code in tests/test_tensorize.py def test_create_dataset_without_augment ( tensor ): \"\"\"[summary]. Args: tensor ([type]): [description] df ([type]): [description] \"\"\" ds = tensor . create_dataset ( \"tests/test_datas/test_datas.csv\" , batch = 5 , repet = 1 , prefetch = 1 , augment = False ) for imgs , _ in ds . take ( 1 ): assert imgs . numpy () . shape == ( 5 , 224 , 224 , 3 )","title":"test_create_dataset_without_augment()"},{"location":"test_tensorize/#tests.test_tensorize.test_load_images","text":"Test of the function load_images . The function should take the column 'filename' of the dataframe en return it as a list. Also checks that we have the right number of elements in the list. Parameters: Name Type Description Default tensor Tensorize [description] required df DataFrame [description] required Source code in tests/test_tensorize.py def test_load_images ( tensor : Tensorize , df : pd . DataFrame ) -> None : \"\"\"Test of the function `load_images`. The function should take the column 'filename' of the dataframe en return it as a list. Also checks that we have the right number of elements in the list. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" filenames = tensor . load_images ( data_frame = df , column_name = \"filename\" ) assert isinstance ( filenames , list ) assert len ( filenames ) == 20 for idx in range ( 20 ): assert isinstance ( filenames [ idx ], str ) image_path = Path ( filenames [ idx ]) assert image_path . is_file ()","title":"test_load_images()"},{"location":"test_tensorize/#tests.test_tensorize.test_load_labels","text":"Test load_labels function. Parameters: Name Type Description Default tensor Tensorize [description] required df DataFrame [description] required Source code in tests/test_tensorize.py def test_load_labels ( tensor : Tensorize , df : pd . DataFrame ) -> None : \"\"\"Test load_labels function. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" zeros = [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] ones = [ 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 ] labels_test = zeros + ones labels_list = tensor . load_labels ( data_frame = df , column_name = \"label\" ) assert len ( labels_list ) == 20 for idx in range ( 20 ): assert labels_list [ idx ] == labels_test [ idx ]","title":"test_load_labels()"},{"location":"test_tensorize/#tests.test_tensorize.test_parse_image_and_label","text":"[summary]. Parameters: Name Type Description Default tensor Tensorize [description] required df DataFrame [description] required Source code in tests/test_tensorize.py def test_parse_image_and_label ( tensor : Tensorize , df : pd . DataFrame ) -> None : \"\"\"[summary]. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" label1 = 0 label2 = 1 img1 , oh_label1 = tensor . parse_image_and_label ( df [ \"filename\" ][ 0 ], label1 ) _ , oh_label2 = tensor . parse_image_and_label ( df [ \"filename\" ][ 10 ], label2 ) assert isinstance ( img1 , tf . Tensor ) assert isinstance ( oh_label1 , tf . Tensor ) assert img1 . numpy () . shape == ( 224 , 224 , 3 ) oh_label10 = oh_label1 . numpy ()[ 0 ] oh_label11 = oh_label1 . numpy ()[ 1 ] oh_label20 = oh_label2 . numpy ()[ 0 ] oh_label21 = oh_label2 . numpy ()[ 1 ] assert ( oh_label10 , oh_label11 ) == ( 1 , 0 ) assert ( oh_label20 , oh_label21 ) == ( 0 , 1 )","title":"test_parse_image_and_label()"},{"location":"test_tensorize/#tests.test_tensorize.test_train_prepocess","text":"[summary]. Parameters: Name Type Description Default tensor Tensorize [description] required df pd.DataFrame [description] required Source code in tests/test_tensorize.py def test_train_prepocess ( tensor : Tensorize ) -> None : \"\"\"[summary]. Args: tensor (Tensorize): [description] df (pd.DataFrame): [description] \"\"\" oh_label = [ 0 , 1 ] img_rdn = np . random . rand ( 224 , 224 , 3 ) img , _ = tensor . train_preprocess ( img_rdn , oh_label ) assert img . numpy () . shape == ( 224 , 224 , 3 )","title":"test_train_prepocess()"},{"location":"test_utils/","text":"Tests unitaires pour le script utils test_cfg ( config_name ) [summary]. Parameters: Name Type Description Default config_name str [description] required Source code in tests/test_utils.py @pytest . mark . parametrize ( \"config_name\" , config_files ) def test_cfg ( config_name : str ) -> None : \"\"\"[summary]. Args: config_name (str): [description] \"\"\" with initialize ( config_path = \"../configs\" ): cfg = compose ( config_name = config_name ) assert isinstance ( cfg , DictConfig ) # check it isn't an empty dict assert bool ( cfg ) test_config_to_hydra_dict ( config_name ) [summary]. Parameters: Name Type Description Default config_name str [description] required Source code in tests/test_utils.py @pytest . mark . parametrize ( \"config_name\" , config_files ) def test_config_to_hydra_dict ( config_name : str ) -> None : \"\"\"[summary]. Args: config_name (str): [description] \"\"\" with initialize ( config_path = \"../configs\" ): cfg = compose ( config_name = config_name ) experiment_dict = config_to_hydra_dict ( cfg ) assert isinstance ( experiment_dict , Dict ) assert bool ( experiment_dict ) test_flatten_omegaconf ( config_name ) [summary]. Parameters: Name Type Description Default config_name str [description] required Source code in tests/test_utils.py @pytest . mark . parametrize ( \"config_name\" , config_files ) def test_flatten_omegaconf ( config_name : str ) -> None : \"\"\"[summary]. Args: config_name (str): [description] \"\"\" with initialize ( config_path = \"../configs\" ): cfg = compose ( config_name = config_name ) flattened_dict = flatten_omegaconf ( cfg ) assert isinstance ( flattened_dict , Dict ) assert bool ( flattened_dict )","title":"utils"},{"location":"test_utils/#tests-unitaires-pour-le-script-utils","text":"","title":"Tests unitaires pour le script utils"},{"location":"test_utils/#tests.test_utils","text":"","title":"tests.test_utils"},{"location":"test_utils/#tests.test_utils.test_cfg","text":"[summary]. Parameters: Name Type Description Default config_name str [description] required Source code in tests/test_utils.py @pytest . mark . parametrize ( \"config_name\" , config_files ) def test_cfg ( config_name : str ) -> None : \"\"\"[summary]. Args: config_name (str): [description] \"\"\" with initialize ( config_path = \"../configs\" ): cfg = compose ( config_name = config_name ) assert isinstance ( cfg , DictConfig ) # check it isn't an empty dict assert bool ( cfg )","title":"test_cfg()"},{"location":"test_utils/#tests.test_utils.test_config_to_hydra_dict","text":"[summary]. Parameters: Name Type Description Default config_name str [description] required Source code in tests/test_utils.py @pytest . mark . parametrize ( \"config_name\" , config_files ) def test_config_to_hydra_dict ( config_name : str ) -> None : \"\"\"[summary]. Args: config_name (str): [description] \"\"\" with initialize ( config_path = \"../configs\" ): cfg = compose ( config_name = config_name ) experiment_dict = config_to_hydra_dict ( cfg ) assert isinstance ( experiment_dict , Dict ) assert bool ( experiment_dict )","title":"test_config_to_hydra_dict()"},{"location":"test_utils/#tests.test_utils.test_flatten_omegaconf","text":"[summary]. Parameters: Name Type Description Default config_name str [description] required Source code in tests/test_utils.py @pytest . mark . parametrize ( \"config_name\" , config_files ) def test_flatten_omegaconf ( config_name : str ) -> None : \"\"\"[summary]. Args: config_name (str): [description] \"\"\" with initialize ( config_path = \"../configs\" ): cfg = compose ( config_name = config_name ) flattened_dict = flatten_omegaconf ( cfg ) assert isinstance ( flattened_dict , Dict ) assert bool ( flattened_dict )","title":"test_flatten_omegaconf()"},{"location":"train/","text":"Boucle d'entra\u00eenement du mod\u00e8le train ( config ) Train loop of the classification model. Lorsque que l'on travaille avec Hydra, toute la logique de la fonction doit \u00eatre contenu dans main() , on ne peut pas faire appel \u00e0 des fonctions tierces ext\u00e9rieures \u00e0 main() , il faut tout coder dedans. De m\u00eame faire attention au dossier root : hydra modifie le dossier root : Path( file ).parent.parent donnera bien . mais cette racine est situ\u00e9e dans le dossier outputs , et non dans vrai dossier racine cracks_defect . Il faut donc ici utiliser hydra.utils.get_original_cwd() pour pouvoir avoir acc\u00e8s au dossier root cracks_defect . Pour changer le learning rate d'un optimiseur apr\u00e8s avoir compil\u00e9 le mod\u00e8le , voir la question StackOverflow suivante. Modifier de lr https://stackoverflow.com/questions/59635474/ whats-difference-between-using-metrics-acc-and-tf-keras-metrics-accuracy I'll just add that as of tf v2.2 in training.py the docs say \"When you pass the strings 'accuracy' or 'acc', we convert this to one of tf.keras.metrics.BinaryAccuracy, tf.keras.metrics.CategoricalAccuracy, tf.keras.metrics.SparseCategoricalAccuracy based on the loss function used and the model output shape. We do a similar conversion for the strings 'crossentropy' and 'ce' as well.\" Parameters: Name Type Description Default config DictConfig [description] required Source code in src/train.py @logger . catch () @hydra . main ( config_path = \"../configs/\" , config_name = \"params.yaml\" ) def train ( config : DictConfig ): \"\"\"Train loop of the classification model. Lorsque que l'on travaille avec Hydra, toute la logique de la fonction doit \u00eatre contenu dans `main()`, on ne peut pas faire appel \u00e0 des fonctions tierces ext\u00e9rieures \u00e0 `main()`, il faut tout coder dedans. De m\u00eame faire attention au dossier root : hydra modifie le dossier root : Path(__file__).parent.parent donnera bien `.` mais cette racine est situ\u00e9e dans le dossier `outputs`, et non dans vrai dossier racine `cracks_defect`. Il faut donc ici utiliser `hydra.utils.get_original_cwd()` pour pouvoir avoir acc\u00e8s au dossier root `cracks_defect`. Pour changer le learning rate d'un optimiseur **apr\u00e8s avoir compil\u00e9 le mod\u00e8le**, voir la question StackOverflow suivante. [Modifier de lr](https://stackoverflow.com/questions/ 59737875/keras-change-learning-rate) https://stackoverflow.com/questions/59635474/ whats-difference-between-using-metrics-acc-and-tf-keras-metrics-accuracy I'll just add that as of tf v2.2 in training.py the docs say \"When you pass the strings 'accuracy' or 'acc', we convert this to one of tf.keras.metrics.BinaryAccuracy, tf.keras.metrics.CategoricalAccuracy, tf.keras.metrics.SparseCategoricalAccuracy based on the loss function used and the model output shape. We do a similar conversion for the strings 'crossentropy' and 'ce' as well.\" Args: config (DictConfig): [description] \"\"\" conf_dict , repo_path = set_log_infos ( config ) logger . info ( \"Setting training policy.\" ) logger . info ( \"test depuis l'env de dev docker\" ) policy = tf . keras . mixed_precision . experimental . Policy ( \"mixed_float16\" ) tf . keras . mixed_precision . experimental . set_policy ( policy ) logger . info ( f \"Compute dtype : { policy . compute_dtype } \" ) logger . info ( f \"Variable dtype : { policy . variable_dtype } \" ) mlflow . set_tracking_uri ( f \"file:// { repo_path } /mlruns\" ) mlflow . set_experiment ( config . mlflow . experiment_name ) set_seed ( config . prepare . seed ) logger . info ( \"Data loading\" ) logger . info ( f \"Root path of the folder : { repo_path } \" ) logger . info ( f \"MLFlow uri : { mlflow . get_tracking_uri () } \" ) with mlflow . start_run ( run_name = config . mlflow . run_name ) as run : logger . info ( f \"Run infos : { run . info } \" ) mltensorflow . autolog ( every_n_iter = 1 ) mlflow . log_params ( flatten_omegaconf ( config )) ts = Tensorize ( n_classes = config . datas . n_classes , img_shape = config . datasets . params . img_shape , random_seed = config . prepare . seed , ) ds = ts . create_dataset ( Path ( repo_path ) / config . datasets . prepared_dataset . train , config . datasets . params . batch_size , config . datasets . params . repetitions , config . datasets . params . prefetch , config . datasets . params . augment , ) ds_val = ts . create_dataset ( Path ( repo_path ) / config . datasets . prepared_dataset . val , config . datasets . params . batch_size , config . datasets . params . repetitions , config . datasets . params . prefetch , config . datasets . params . augment , ) logger . info ( \"Compiling model\" ) cnn = load_obj ( config . cnn . class_name ) model = cnn ( ** conf_dict [ \"cnn.params\" ]) optim = load_obj ( config . optimizer . class_name ) optimizer = optim ( ** conf_dict [ \"optimizer.params\" ]) loss = load_obj ( config . losses . class_name ) loss = loss ( ** conf_dict [ \"losses.params\" ]) metric = load_obj ( config . metrics . class_name ) metric = metric () model . compile ( optimizer = optimizer , loss = loss , metrics = [ metric ], ) logger . info ( \"Start training\" ) model . fit ( ds , epochs = config . training . epochs , validation_data = ds_val , )","title":"Boucle d'entra\u00eenement"},{"location":"train/#boucle-dentrainement-du-modele","text":"","title":"Boucle d'entra\u00eenement du mod\u00e8le"},{"location":"train/#src.train","text":"","title":"src.train"},{"location":"train/#src.train.train","text":"Train loop of the classification model. Lorsque que l'on travaille avec Hydra, toute la logique de la fonction doit \u00eatre contenu dans main() , on ne peut pas faire appel \u00e0 des fonctions tierces ext\u00e9rieures \u00e0 main() , il faut tout coder dedans. De m\u00eame faire attention au dossier root : hydra modifie le dossier root : Path( file ).parent.parent donnera bien . mais cette racine est situ\u00e9e dans le dossier outputs , et non dans vrai dossier racine cracks_defect . Il faut donc ici utiliser hydra.utils.get_original_cwd() pour pouvoir avoir acc\u00e8s au dossier root cracks_defect . Pour changer le learning rate d'un optimiseur apr\u00e8s avoir compil\u00e9 le mod\u00e8le , voir la question StackOverflow suivante. Modifier de lr https://stackoverflow.com/questions/59635474/ whats-difference-between-using-metrics-acc-and-tf-keras-metrics-accuracy I'll just add that as of tf v2.2 in training.py the docs say \"When you pass the strings 'accuracy' or 'acc', we convert this to one of tf.keras.metrics.BinaryAccuracy, tf.keras.metrics.CategoricalAccuracy, tf.keras.metrics.SparseCategoricalAccuracy based on the loss function used and the model output shape. We do a similar conversion for the strings 'crossentropy' and 'ce' as well.\" Parameters: Name Type Description Default config DictConfig [description] required Source code in src/train.py @logger . catch () @hydra . main ( config_path = \"../configs/\" , config_name = \"params.yaml\" ) def train ( config : DictConfig ): \"\"\"Train loop of the classification model. Lorsque que l'on travaille avec Hydra, toute la logique de la fonction doit \u00eatre contenu dans `main()`, on ne peut pas faire appel \u00e0 des fonctions tierces ext\u00e9rieures \u00e0 `main()`, il faut tout coder dedans. De m\u00eame faire attention au dossier root : hydra modifie le dossier root : Path(__file__).parent.parent donnera bien `.` mais cette racine est situ\u00e9e dans le dossier `outputs`, et non dans vrai dossier racine `cracks_defect`. Il faut donc ici utiliser `hydra.utils.get_original_cwd()` pour pouvoir avoir acc\u00e8s au dossier root `cracks_defect`. Pour changer le learning rate d'un optimiseur **apr\u00e8s avoir compil\u00e9 le mod\u00e8le**, voir la question StackOverflow suivante. [Modifier de lr](https://stackoverflow.com/questions/ 59737875/keras-change-learning-rate) https://stackoverflow.com/questions/59635474/ whats-difference-between-using-metrics-acc-and-tf-keras-metrics-accuracy I'll just add that as of tf v2.2 in training.py the docs say \"When you pass the strings 'accuracy' or 'acc', we convert this to one of tf.keras.metrics.BinaryAccuracy, tf.keras.metrics.CategoricalAccuracy, tf.keras.metrics.SparseCategoricalAccuracy based on the loss function used and the model output shape. We do a similar conversion for the strings 'crossentropy' and 'ce' as well.\" Args: config (DictConfig): [description] \"\"\" conf_dict , repo_path = set_log_infos ( config ) logger . info ( \"Setting training policy.\" ) logger . info ( \"test depuis l'env de dev docker\" ) policy = tf . keras . mixed_precision . experimental . Policy ( \"mixed_float16\" ) tf . keras . mixed_precision . experimental . set_policy ( policy ) logger . info ( f \"Compute dtype : { policy . compute_dtype } \" ) logger . info ( f \"Variable dtype : { policy . variable_dtype } \" ) mlflow . set_tracking_uri ( f \"file:// { repo_path } /mlruns\" ) mlflow . set_experiment ( config . mlflow . experiment_name ) set_seed ( config . prepare . seed ) logger . info ( \"Data loading\" ) logger . info ( f \"Root path of the folder : { repo_path } \" ) logger . info ( f \"MLFlow uri : { mlflow . get_tracking_uri () } \" ) with mlflow . start_run ( run_name = config . mlflow . run_name ) as run : logger . info ( f \"Run infos : { run . info } \" ) mltensorflow . autolog ( every_n_iter = 1 ) mlflow . log_params ( flatten_omegaconf ( config )) ts = Tensorize ( n_classes = config . datas . n_classes , img_shape = config . datasets . params . img_shape , random_seed = config . prepare . seed , ) ds = ts . create_dataset ( Path ( repo_path ) / config . datasets . prepared_dataset . train , config . datasets . params . batch_size , config . datasets . params . repetitions , config . datasets . params . prefetch , config . datasets . params . augment , ) ds_val = ts . create_dataset ( Path ( repo_path ) / config . datasets . prepared_dataset . val , config . datasets . params . batch_size , config . datasets . params . repetitions , config . datasets . params . prefetch , config . datasets . params . augment , ) logger . info ( \"Compiling model\" ) cnn = load_obj ( config . cnn . class_name ) model = cnn ( ** conf_dict [ \"cnn.params\" ]) optim = load_obj ( config . optimizer . class_name ) optimizer = optim ( ** conf_dict [ \"optimizer.params\" ]) loss = load_obj ( config . losses . class_name ) loss = loss ( ** conf_dict [ \"losses.params\" ]) metric = load_obj ( config . metrics . class_name ) metric = metric () model . compile ( optimizer = optimizer , loss = loss , metrics = [ metric ], ) logger . info ( \"Start training\" ) model . fit ( ds , epochs = config . training . epochs , validation_data = ds_val , )","title":"train()"}]}